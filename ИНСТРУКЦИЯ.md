# Инструкция по запуску LDA оптимизации

## Содержимое проекта:

- `lda_optimizer.py` - основной скрипт оптимизации
- `Dockerfile` - конфигурация Docker образа
- `requirements.txt` - Python зависимости
- `build.sh` - скрипт для сборки Docker образа
- `run.sh` - скрипт для запуска оптимизации
- `data/` - папка с датасетами (validation выборки, .npz файлы)

## Методология:

**Правильный подход к подбору гиперпараметров LDA:**
1. Обучаем LDA на **validation** выборке
2. Оптимизируем для минимизации средней **perplexity** на той же validation выборке
3. Используем генетический алгоритм (GA) для поиска оптимального T
4. Alpha и eta автоматически устанавливаются как 1/T

## Быстрый старт:

### Вариант 1: Локальный запуск

```bash
python lda_optimizer.py
```

### Вариант 2: Docker запуск

```bash
# 1. Собрать Docker образ
./build.sh

# 2. Запустить оптимизацию
./run.sh
```

## Подробная инструкция:

### Шаг 1: Собрать Docker образ (опционально)

```bash
./build.sh
```

Или вручную:
```bash
docker build -t lda-optimizer .
```

### Шаг 2: Запустить оптимизацию

```bash
./run.sh
```

Или вручную:
```bash
mkdir -p logs
docker run -v $(pwd)/logs:/app/logs lda-optimizer
```

**Что происходит:**
- Запускается оптимизация на 4 датасетах: 20news, agnews, val_out, yelp
- Для каждого датасета ищется оптимальное T (число топиков)
- Обучение происходит на validation выборке
- Перплексия считается на той же validation выборке
- Early stopping: если перплексия не улучшается >1% за 3 итерации

### Шаг 3: Результаты

Результаты сохраняются в `logs/`:

```
logs/
├── 20news/
│   ├── tensorboard/      # TensorBoard логи
│   ├── history.csv       # История оптимизации
│   ├── summary.json      # Итоговые результаты
│   ├── perplexity.png    # График перплексии
│   ├── T_over_time.png   # График T
│   └── population_*.csv  # Популяции по поколениям
├── agnews/
├── val_out/
├── yelp/
└── all_results.json      # Сводные результаты
```

### Посмотреть прогресс в реальном времени:

```bash
# Если запущен в Docker
docker ps
docker logs -f <CONTAINER_ID>
```

### TensorBoard:

```bash
tensorboard --logdir=logs/
```

Откройте в браузере: http://localhost:6006

## Параметры оптимизации:

- **Алгоритм:** Genetic Algorithm (GA)
- **Популяция:** 10 особей
- **Элитизм:** 5 лучших особей
- **Максимум поколений:** 200 (с early stopping)
- **LDA max_iter:** 60
- **Batch size:** 2048
- **Learning method:** online
- **Early stopping:** если изменение <1% за 3 итерации подряд

## Датасеты:

Используются только validation выборки:
- `data/X_20news_val_bow.npz`
- `data/X_agnews_val_bow.npz`
- `data/X_val_out_val_bow.npz`
- `data/X_yelp_val_bow.npz`