% ============================================================================
% ALGORITHMS SECTION
% ============================================================================

\subsection{Algorithms}

We compare three black-box optimization methods for selecting the optimal number of topics $T$ in LDA. All algorithms operate under the same conditions: they start from an identical initial population and run for exactly 20 iterations without early stopping, ensuring a fair comparison with a fixed computational budget.

% ----------------------------------------------------------------------------
\subsubsection{Genetic Algorithm (GA)}

The Genetic Algorithm maintains a population of $N_{\text{pop}} = 20$ candidate solutions and evolves them through selection, crossover, and mutation operations.

\paragraph{Selection.} Tournament selection is employed: for each position in the new population, $k$ individuals are randomly sampled from the current population, and the one with the best fitness (lowest perplexity) is chosen.

\paragraph{Crossover.} With probability $p_c = 0.9$, two selected parents undergo binary crossover. Each candidate $T$ is represented in binary form, and offspring are generated by combining bit strings from both parents. Specifically, a crossover point is randomly chosen, and the binary representations are split and recombined:
\[
T_{\text{child}_1} = [T_{\text{parent}_1}[1:k], T_{\text{parent}_2}[k+1:]], \quad
T_{\text{child}_2} = [T_{\text{parent}_2}[1:k], T_{\text{parent}_1}[k+1:]],
\]
where $k$ is the crossover point. This allows offspring to inherit structural properties from both parents.

\paragraph{Mutation.} With probability $p_m = 0.2$, an individual undergoes mutation by randomly flipping one or more bits in its binary representation, or equivalently, by adding Gaussian noise (clipped to $[T_{\min}, T_{\max}]$) to the integer value of $T$.

\paragraph{Elitism.} The top $N_{\text{elite}} = 5$ individuals from the current generation are guaranteed to survive into the next generation unchanged, preserving the best solutions found so far.

\paragraph{Algorithm summary:}
\begin{enumerate}
    \item Initialize population $P_0$ with 20 random values of $T \in [2, 1000]$
    \item For $t = 1, \ldots, 20$:
    \begin{enumerate}
        \item Evaluate fitness (perplexity) for all $T \in P_{t-1}$
        \item Select parents via tournament selection
        \item Generate offspring via crossover (prob. $p_c$) and mutation (prob. $p_m$)
        \item Keep top $N_{\text{elite}}$ individuals (elitism)
        \item Form new population $P_t$
    \end{enumerate}
    \item Return best $T^*$ from final population $P_{20}$
\end{enumerate}

% ----------------------------------------------------------------------------
\subsubsection{Evolution Strategy (ES)}

Evolution Strategy follows a $(\mu, \lambda)$-ES scheme, where $\mu = 5$ parents generate $\lambda = 10$ offspring, and only the best $\mu$ offspring (not including parents) survive to the next generation.

\paragraph{Offspring generation.} Each of the $\mu$ parents produces $\lambda / \mu = 2$ offspring through mutation:
\[
T_{\text{offspring}} = T_{\text{parent}} + \mathcal{N}(0, \sigma^2),
\]
where $\sigma$ is an adaptive step size parameter. The mutated value is clipped to the bounds $[T_{\min}, T_{\max}] = [2, 1000]$ and rounded to the nearest integer.

\paragraph{Selection.} After evaluating the fitness (perplexity) of all $\lambda$ offspring, the best $\mu$ individuals become the parents for the next generation. Importantly, parents do not compete with their offspring (comma-selection), ensuring that the population does not stagnate.

\paragraph{Adaptive step size.} The mutation variance $\sigma^2$ may be adapted over generations based on the success rate of mutations, though in the current implementation a fixed or slowly decaying $\sigma$ is used.

\paragraph{Algorithm summary:}
\begin{enumerate}
    \item Initialize $\mu = 5$ parents from initial population
    \item For $t = 1, \ldots, 20$:
    \begin{enumerate}
        \item Generate $\lambda = 10$ offspring by mutating parents
        \item Evaluate fitness (perplexity) for all offspring
        \item Select $\mu$ best offspring as new parents (comma-selection)
    \end{enumerate}
    \item Return best $T^*$ from final parent set
\end{enumerate}

% ----------------------------------------------------------------------------
\subsubsection{PABBO Full}

PABBO (Preferential Amortized Black-Box Optimization) leverages a pre-trained Transformer-based model to guide the search using preference-based feedback. Unlike GA and ES, which rely solely on absolute fitness values, PABBO learns from pairwise comparisons of the form ``$T_i$ yields better perplexity than $T_j$''.

\paragraph{Preference learning.} The core of PABBO is a Transformer model with the following architecture:
\begin{itemize}
    \item \textbf{Embedding layer} (depth 2): maps each candidate $T$ and its associated perplexity into a latent space $\mathbb{R}^{d_{\text{model}}}$ with $d_{\text{model}} = 32$
    \item \textbf{Transformer encoder} (3 layers, 2 attention heads, feedforward dimension 64): processes the history of past evaluations $H_t = \{(T_i, \text{perplexity}_i)\}_{i=1}^t$ to capture dependencies and learn a surrogate model of the objective landscape
    \item \textbf{Acquisition head}: outputs scores for candidate pairs $(T_i, T_j)$, which are used to select the next point to evaluate via a softmax policy $\pi_{\theta}(a_t \mid H_t)$
    \item \textbf{Prediction head}: performs auxiliary preference prediction to stabilize training
\end{itemize}

\paragraph{Acquisition strategy.} At each iteration $t$, PABBO:
\begin{enumerate}
    \item Encodes the current optimization history $H_t$ using the Transformer
    \item Generates candidate pairs from a query set (e.g., by sampling or using a grid)
    \item Computes acquisition scores for each pair via the acquisition head
    \item Selects the pair with the highest score (exploitation) or samples from the softmax distribution (exploration/exploitation trade-off)
    \item Evaluates the chosen $T$ and updates the history $H_{t+1} = H_t \cup \{(T, \text{perplexity})\}$
\end{enumerate}

The exploration rate $\epsilon = 0.3$ balances between exploiting the current best region and exploring new areas of the search space.

\paragraph{Model training.} The Transformer model is trained offline on a distribution of synthetic optimization tasks (e.g., 1D Rastrigin and Gaussian Process functions) using reinforcement learning to maximize the best discovered function value within a fixed query budget. This meta-learning phase allows PABBO to generalize to new optimization problems, including LDA hyperparameter tuning, without task-specific retraining.

\paragraph{Algorithm summary:}
\begin{enumerate}
    \item Load pre-trained PABBO Transformer model (checkpoint: \texttt{ckpt.tar})
    \item Initialize history $H_0$ with initial population evaluations
    \item For $t = 1, \ldots, 20$:
    \begin{enumerate}
        \item Encode history $H_{t-1}$ via Transformer
        \item Compute acquisition scores for candidate $T$ values
        \item Select next $T_t$ via acquisition policy (exploration rate $\epsilon = 0.3$)
        \item Evaluate perplexity for $T_t$
        \item Update history $H_t = H_{t-1} \cup \{(T_t, \text{perplexity}(T_t))\}$
    \end{enumerate}
    \item Return $T^* = \arg\min_{T \in H_{20}} \text{perplexity}(T)$
\end{enumerate}

% ----------------------------------------------------------------------------
\subsubsection{Common Parameters}

All three algorithms share the following configuration:
\begin{itemize}
    \item \textbf{Search space:} $T \in [2, 1000]$ (integers)
    \item \textbf{Initial population:} 20 values randomly sampled with seed 42: \\
    $\{733, 811, 133, 355, 777, 115, 452, 940, 879, 345, 576, 153, 950, 602, 162, 238, 422, 511, 660, 285\}$
    \item \textbf{Optimization budget:} exactly 20 iterations per run (no early stopping)
    \item \textbf{Hyperparameters:} $\alpha = \eta = 1/T$ (symmetric Dirichlet priors)
    \item \textbf{Objective:} minimize perplexity on validation corpus $\mathcal{D}_{\text{val}}$
\end{itemize}

The identical initial population and fixed iteration budget ensure a fair comparison across methods.


% ============================================================================
% EXPERIMENTAL SETUP SECTION
% ============================================================================

\subsection{Experimental Setup}

We conduct a comprehensive evaluation of the three optimization algorithms (GA, ES, PABBO Full) on multiple text corpora. The experimental pipeline consists of four main stages.

% ----------------------------------------------------------------------------
\subsubsection{Stage 1: PABBO Model Training}

Before running LDA experiments, we train the PABBO Transformer model from scratch using the configuration \texttt{train\_rastrigin1d\_test}. The model is trained on synthetic 1D optimization tasks (Rastrigin function and Gaussian Process samples) to learn a general-purpose optimization policy.

\textbf{Model architecture:}
\begin{itemize}
    \item Embedding dimension: $d_{\text{model}} = 32$
    \item Number of layers: $L = 3$
    \item Attention heads: $n_{\text{head}} = 2$
    \item Feedforward dimension: $d_{\text{ff}} = 64$
    \item Embedding depth: 2 layers
\end{itemize}

\textbf{Training details:}
\begin{itemize}
    \item Training functions: 1D Rastrigin, GP with RBF kernel
    \item Context points: randomly sampled 5--20 points per episode
    \item Query budget: 20 evaluations per episode
    \item Optimizer: Adam with learning rate scheduling
    \item Training time: approximately 10--30 minutes on CPU
\end{itemize}

The trained model checkpoint (\texttt{ckpt.tar}) is saved and subsequently used in the PABBO Full algorithm for LDA optimization.

% ----------------------------------------------------------------------------
\subsubsection{Stage 2: Model Validation}

The trained PABBO model is evaluated on a held-out set of 1D Gaussian Process functions to verify its generalization capability. Evaluation is performed on 256 query points uniformly distributed over the input domain $[-1, 1]$, with context sets of size 5--20. While this stage is not critical for the LDA experiments, it provides confidence that the model has learned a meaningful optimization policy.

% ----------------------------------------------------------------------------
\subsubsection{Stage 3: LDA Hyperparameter Optimization}

This is the core experimental stage, where all three algorithms are applied to optimize the number of topics $T$ for LDA models trained on real text corpora.

\paragraph{Datasets.} We use preprocessed text corpora in bag-of-words (BoW) format, stored as sparse matrices (\texttt{scipy.sparse}) in \texttt{.npz} files. Each dataset contains:
\begin{itemize}
    \item $M$ documents (rows)
    \item $V$ vocabulary terms (columns)
    \item Non-zero entries $n_{dw}$ representing word counts
\end{itemize}

Datasets are automatically discovered from the \texttt{data/} directory by matching the pattern \texttt{X\_*\_val\_bow.npz}. Examples of corpora used include 20 Newsgroups, Reuters, and other publicly available text collections.

\paragraph{LDA training configuration.} For each candidate $T$, an LDA model is trained using the following parameters:
\begin{itemize}
    \item \textbf{Learning method:} online variational inference
    \item \textbf{Maximum iterations:} 60
    \item \textbf{Batch size:} 2048 documents
    \item \textbf{Hyperparameters:} $\alpha = \eta = 1/T$ (symmetric Dirichlet priors)
    \item \textbf{Random seed:} $42 + r$, where $r \in \{0, 1, \ldots, 9\}$ is the run index
\end{itemize}

After training, the model's perplexity is computed on the validation corpus $\mathcal{D}_{\text{val}}$ as:
\[
\text{Perplexity}(\mathcal{D}_{\text{val}}) = \exp\left( -\frac{\sum_{d,w} n_{dw} \ln p(w \mid d)}{\sum_{d,w} n_{dw}} \right).
\]

\paragraph{Optimization protocol.} For each dataset and each run $r \in \{0, \ldots, 9\}$:
\begin{enumerate}
    \item Load the initial population of 20 values of $T$ from \texttt{lda\_init\_population.json}
    \item Run GA, ES, and PABBO Full in parallel (or sequentially), each performing exactly 20 iterations
    \item For each iteration $t$:
    \begin{itemize}
        \item The algorithm proposes one or more candidate values of $T$
        \item For each $T$, train an LDA model and compute perplexity
        \item Update the algorithm's internal state (population, history, etc.)
        \item Log the best $T$ and best perplexity found so far
    \end{itemize}
    \item Save results: best $T^*$, best perplexity, optimization history, and total time
\end{enumerate}

\paragraph{No early stopping.} Critically, \textbf{early stopping is disabled} in all algorithms (by setting \texttt{early\_stop\_eps\_pct=0.0} and \texttt{max\_no\_improvement=999999}). This ensures that every algorithm uses exactly 20 LDA training iterations, making the comparison fair and eliminating bias from differing convergence rates.

\paragraph{Repetitions.} Each (dataset, algorithm) combination is repeated 10 times with different random seeds ($42, 43, \ldots, 51$) to assess statistical significance and stability.

\paragraph{Computational resources.} All experiments are run on CPU. Each single experiment (one dataset, one run, three algorithms) takes approximately 20--40 minutes. The total experimental time for $N_{\text{datasets}}$ datasets is:
\[
T_{\text{total}} = N_{\text{datasets}} \times 10 \text{ runs} \times (20\text{--}40 \text{ min}) \approx 40\text{--}80 \text{ hours (sequential)}.
\]
With parallelization across 10 workers, this reduces to approximately 4--8 hours.

\paragraph{Logged metrics.} For each algorithm and run, the following metrics are recorded:
\begin{itemize}
    \item \textbf{best\_T}: optimal number of topics found
    \item \textbf{best\_perplexity}: minimum perplexity achieved
    \item \textbf{total\_time}: wall-clock time for 20 iterations (seconds)
    \item \textbf{avg\_step\_time}: average time per iteration
    \item \textbf{num\_iterations}: number of iterations executed (always 20)
    \item \textbf{history}: trajectory of $(T_t, \text{perplexity}_t)$ over iterations
\end{itemize}

All results are saved in JSON format for downstream analysis.

% ----------------------------------------------------------------------------
\subsubsection{Stage 4: Aggregation and Visualization}

After all experiments complete, results are aggregated across runs and datasets to compute summary statistics and generate visualizations for the paper.

\paragraph{Statistical aggregation.} For each (dataset, algorithm) pair, we compute:
\begin{itemize}
    \item \textbf{Mean perplexity:} $\bar{p} = \frac{1}{10} \sum_{r=1}^{10} p_r$
    \item \textbf{Standard deviation:} $\sigma_p = \sqrt{\frac{1}{9} \sum_{r=1}^{10} (p_r - \bar{p})^2}$
    \item \textbf{Minimum perplexity:} $p_{\min} = \min_{r=1}^{10} p_r$
    \item \textbf{Maximum perplexity:} $p_{\max} = \max_{r=1}^{10} p_r$
    \item \textbf{Mean time:} $\bar{t}$ and standard deviation $\sigma_t$
\end{itemize}

These statistics are saved in \texttt{statistics.json} and \texttt{all\_results.csv}.

\paragraph{Visualization.} The following plots are generated in both PNG (high resolution for presentations) and SVG (vector format for publications):
\begin{enumerate}
    \item \textbf{Perplexity comparison (bar charts):} For each dataset, a bar chart displays mean perplexity $\pm$ standard deviation for GA, ES, and PABBO Full.
    \item \textbf{Time comparison (grouped bar chart):} Shows mean optimization time for each algorithm across datasets.
    \item \textbf{Perplexity distribution (box plots):} For each dataset, box plots display the distribution of perplexity over 10 runs, revealing stability and outliers.
    \item \textbf{Convergence curves:} Line plots show the best perplexity found over iterations (and over time) for each algorithm, illustrating convergence speed.
\end{enumerate}

\paragraph{Statistical significance testing.} To determine whether differences between algorithms are statistically significant, we apply:
\begin{itemize}
    \item \textbf{Wilcoxon signed-rank test:} pairwise comparison of GA vs.\ ES, GA vs.\ PABBO, and ES vs.\ PABBO (paired test across datasets and runs)
    \item \textbf{Friedman test:} non-parametric test for comparing all three algorithms simultaneously
    \item \textbf{Effect size (Cohen's $d$):} quantifies the magnitude of differences
\end{itemize}

Results are reported as $p$-values in a summary table in the Results section.

% ----------------------------------------------------------------------------
\subsubsection{Reproducibility}

All aspects of the experimental pipeline are designed for full reproducibility:
\begin{itemize}
    \item \textbf{Fixed seeds:} 42 for initial population generation; $42 + r$ for run $r$
    \item \textbf{Initial population saved:} \texttt{lda\_init\_population.json} contains the exact 20 starting values of $T$
    \item \textbf{Deterministic LDA training:} seeds are set for scikit-learn's \texttt{LatentDirichletAllocation}
    \item \textbf{No early stopping:} ensures identical iteration budgets
    \item \textbf{Logged configurations:} all hyperparameters and model checkpoints are versioned and saved
\end{itemize}

The complete pipeline is implemented in a single script (\texttt{lda.py}), which sequentially executes all four stages and produces a timestamped output directory containing logs, plots, and result files.
