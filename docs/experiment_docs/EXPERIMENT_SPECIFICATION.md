# Спецификация экспериментальной установки для LDA оптимизации

## Общая структура pipeline

Экспериментальный pipeline состоит из 4 основных этапов:

### ЭТАП 1: Обучение PABBO модели
**Цель**: Обучить трансформерную модель для эффективного поиска гиперпараметров

**Процесс**:
1. Используется конфигурация `train_rastrigin1d_test` (облегченная версия для быстрого тестирования)
2. Модель обучается на функции Растригина 1D
3. Выход: файл `ckpt.tar` с весами обученной модели

**Характеристики модели**:
- Архитектура: Transformer-based
- Параметры: d_model=32, n_layers=3, nhead=2, dim_feedforward=64, emb_depth=2
- Обучение: на synthetic функциях оптимизации (GP1D)

---

### ЭТАП 2: Валидация PABBO модели
**Цель**: Проверить качество обученной модели перед использованием в LDA экспериментах

**Процесс**:
1. Evaluation на GP1D функции с параметрами:
   - Входное пространство: 1D, диапазон [-1, 1]
   - Контекстные точки: от 5 до 20
   - Query points: 256
2. Оценка предсказаний модели на тестовых данных
3. Выход: метрики качества модели (опционально, не критично для pipeline)

---

### ЭТАП 3: LDA Hyperparameter Optimization
**Цель**: Оптимизация числа топиков (T) для LDA на реальных текстовых датасетах

#### 3.1 Описание задачи оптимизации

**Целевая функция**: Минимизация перплексии (perplexity) на валидационном множестве

**Пространство поиска**:
- Параметр T (число топиков): [2, 1000]
- Параметры α (alpha) и η (eta): фиксированы как 1/T (symmetric Dirichlet prior)

**LDA параметры**:
- Метод обучения: online variational inference
- Максимальное число итераций: 60
- Batch size: 2048
- Random seed: 42 + run_id (для воспроизводимости)

#### 3.2 Датасеты

Используются preprocessed текстовые корпуса в формате Bag-of-Words:
- Расположение: `/data/X_{dataset_name}_val_bow.npz`
- Форматы: sparse matrix (scipy.sparse)
- Обнаруженные датасеты автоматически определяются по маске файлов

Примеры возможных датасетов:
- 20newsgroups
- reuters
- wikitext
- другие текстовые корпуса

#### 3.3 Алгоритмы оптимизации

Сравниваются 3 метода оптимизации:

##### 3.3.1 Genetic Algorithm (GA)
**Тип**: Эволюционный алгоритм

**Гиперпараметры**:
- Population size: 20 (из initial_population)
- Crossover probability (cxpb): 0.9
- Mutation probability (mutpb): 0.2
- Elite size: 5 (сохранение лучших решений)
- T bounds: [2, 1000]

**Механизм**:
1. Инициализация популяции из фиксированного набора
2. Selection: tournament selection
3. Crossover: одноточечный или двухточечный
4. Mutation: случайные изменения генов в допустимых границах
5. Elitism: лучшие 5 решений переходят в следующее поколение

##### 3.3.2 Evolution Strategy (ES)
**Тип**: (μ, λ)-ES

**Гиперпараметры**:
- μ (parents): 5
- λ (offspring): 10
- T bounds: [2, 1000]

**Механизм**:
1. Инициализация μ родителей из initial_population
2. Генерация λ потомков через мутацию родителей
3. Selection: выбор μ лучших из λ потомков (не из родителей + потомков)
4. Адаптивная стратегия мутации

##### 3.3.3 PABBO_Full
**Тип**: Bayesian Optimization с Transformer моделью

**Гиперпараметры**:
- Exploration rate: 0.3
- Model: обученная Transformer модель из ЭТАПА 1
- T bounds: [2, 1000]

**Механизм**:
1. Инициализация из initial_population
2. Использование обученной Transformer модели для предсказания перспективных областей поиска
3. Acquisition function: balance между exploration и exploitation
4. Адаптивный выбор следующих точек на основе истории оптимизации

#### 3.4 Экспериментальный протокол

**Инициализация**:
- Все алгоритмы стартуют с одинаковой initial population из файла `lda_init_population.json`
- Population size: 20 значений T
- Seed: 42 для генерации начальной популяции
- Пример: [733, 811, 133, 355, 777, 115, 452, 940, 879, 345, 576, 153, 950, 602, 162, 238, 422, 511, 660, 285]

**Параметры запуска**:
- Число итераций: **20** (фиксировано, БЕЗ early stopping)
- Число повторений: **10** (для статистической значимости)
- Seeds для run_id: 42, 43, 44, ..., 51
- Timeout: 2 часа на один эксперимент

**Важно**:
- Early stopping ОТКЛЮЧЕН (`early_stop_eps_pct=0.0`, `max_no_improvement=999999`)
- Все алгоритмы выполняют ровно 20 итераций
- Это обеспечивает честное сравнение по фиксированному бюджету оптимизации

#### 3.5 Метрики и логирование

**Сохраняемые метрики для каждого алгоритма**:
- `best_T`: лучшее найденное число топиков
- `best_alpha`, `best_eta`: соответствующие гиперпараметры (1/T)
- `best_perplexity`: минимальная достигнутая perplexity
- `total_time`: общее время оптимизации (секунды)
- `avg_step_time`: среднее время одной итерации
- `num_iterations`: число выполненных итераций (=20)
- `history`: траектория оптимизации (perplexity по итерациям)

**Структура выходных файлов**:
```
lda_pipeline_results/
└── run_{timestamp}/
    ├── logs/
    │   ├── pipeline_main.log
    │   └── pipeline_metrics.json
    ├── experiments/
    │   ├── {dataset_name}/
    │   │   ├── run_0/
    │   │   │   ├── GA/
    │   │   │   │   ├── summary.json
    │   │   │   │   ├── history.csv
    │   │   │   │   └── optimization_plots.png
    │   │   │   ├── ES/
    │   │   │   │   └── ...
    │   │   │   └── PABBO_Full/
    │   │   │       └── ...
    │   │   ├── run_1/
    │   │   │   └── ...
    │   │   ...
    │   │   └── run_9/
    │   │       └── ...
    ├── all_results.json
    └── aggregated_results/
        ├── all_results.csv
        ├── statistics.json
        ├── perplexity_comparison.png
        ├── perplexity_comparison.svg
        ├── time_comparison.png
        ├── time_comparison.svg
        ├── perplexity_boxplots.png
        └── perplexity_boxplots.svg
```

---

### ЭТАП 4: Агрегация результатов и визуализация

**Цель**: Статистический анализ и сравнение алгоритмов

#### 4.1 Сбор данных

**Процесс**:
1. Сбор всех `summary.json` из 10 запусков × N датасетов × 3 алгоритма
2. Фильтрация успешных экспериментов (status='SUCCESS')
3. Создание сводной таблицы (DataFrame)

**Колонки DataFrame**:
- dataset: название датасета
- run_id: номер повторения (0-9)
- algorithm: GA, ES, или PABBO_Full
- best_T: оптимальное число топиков
- best_perplexity: достигнутая perplexity
- total_time: время оптимизации
- elapsed_time: общее время эксперимента
- num_iterations: число итераций

#### 4.2 Статистический анализ

**Вычисляемые метрики для каждой пары (датасет, алгоритм)**:
- **mean_perplexity**: среднее значение best_perplexity по 10 запускам
- **std_perplexity**: стандартное отклонение perplexity
- **min_perplexity**: лучший результат из 10 запусков
- **max_perplexity**: худший результат из 10 запусков
- **mean_time**: среднее время оптимизации
- **std_time**: стандартное отклонение времени
- **num_runs**: число успешных запусков

**Формат выходного файла** (`statistics.json`):
```json
{
  "20news": {
    "GA": {
      "mean_perplexity": 1234.56,
      "std_perplexity": 45.67,
      "min_perplexity": 1180.23,
      "max_perplexity": 1290.45,
      "mean_time": 234.12,
      "std_time": 12.34,
      "num_runs": 10
    },
    "ES": { ... },
    "PABBO_Full": { ... }
  },
  ...
}
```

#### 4.3 Визуализация результатов

##### 4.3.1 Perplexity Comparison (perplexity_comparison.png/svg)
**Тип**: 2×2 grid bar charts с error bars

**Содержание**:
- По одному subplot на каждый датасет (до 4 датасетов)
- X-axis: алгоритмы (GA, ES, PABBO_Full)
- Y-axis: perplexity (lower is better)
- Error bars: стандартное отклонение по 10 запускам
- Для каждого алгоритма: высота столбца = mean_perplexity

**Назначение**: Быстрое визуальное сравнение качества алгоритмов

##### 4.3.2 Time Comparison (time_comparison.png/svg)
**Тип**: Grouped bar chart

**Содержание**:
- X-axis: датасеты
- Y-axis: время (секунды)
- Группы bars: по алгоритму
- Высота: mean_time по 10 запускам

**Назначение**: Сравнение вычислительной эффективности

##### 4.3.3 Perplexity Distribution (perplexity_boxplots.png/svg)
**Тип**: 2×2 grid box plots

**Содержание**:
- По одному subplot на каждый датасет
- X-axis: алгоритмы
- Y-axis: perplexity
- Box plot: показывает распределение по 10 запускам (median, quartiles, outliers)

**Назначение**:
- Оценка стабильности алгоритмов
- Выявление outliers
- Визуализация variance

##### 4.3.4 Individual Optimization Plots (optimization_plots.png/svg)
**Создаются для каждого запуска отдельно**

**Тип**: 2×2 grid line plots

**Содержание**:
1. **Perplexity vs Iteration**: сходимость по итерациям
2. **Perplexity vs Time**: сходимость по времени
3. **T vs Iteration**: траектория параметра T
4. **T vs Time**: изменение T во времени

**Назначение**: Детальный анализ поведения алгоритма в конкретном запуске

---

## Статистическая значимость

**Количество экспериментов**:
- Total = N_datasets × 10_runs × 3_algorithms
- Если N_datasets = 4, то Total = 120 экспериментов

**Обеспечение воспроизводимости**:
1. Фиксированный seed для initial population (42)
2. Разные seeds для runs: 42 + run_id (42, 43, ..., 51)
3. Одинаковая initial population для всех алгоритмов в каждом run
4. Фиксированное число итераций (20, без early stopping)

**Методы сравнения** (для статьи):
- Paired statistical tests (т.к. все алгоритмы тестируются на одних датасетах)
- Wilcoxon signed-rank test (для парного сравнения)
- Friedman test (для сравнения трех алгоритмов)
- Effect size: Cohen's d или аналоги

---

## Вычислительные ресурсы

**На один эксперимент**:
- CPU: используется для всех вычислений
- Параллелизация: по датасетам и runs (sequential внутри pipeline)
- Таймауты:
  - Обучение PABBO: 1 час
  - Evaluation PABBO: 30 минут
  - Один LDA эксперимент: 2 часа

**Total времени (ориентировочно)**:
- ЭТАП 1 (обучение PABBO): ~10-30 минут (light model)
- ЭТАП 2 (evaluation): ~5-10 минут
- ЭТАП 3 (LDA optimization): зависит от числа датасетов
  - Один эксперимент (dataset × run × 3 algorithms): ~20-40 минут
  - Total для 4 датасетов × 10 runs: ~40-80 часов (если sequential)
- ЭТАП 4 (агрегация): ~1-5 минут

**Оптимизация**:
- Можно запускать параллельно разные (dataset, run) комбинации
- При параллелизации по 10 процессам: ~4-8 часов total

---

## Параметры для воспроизведения

```python
# PABBO Training
config = "train_rastrigin1d_test"
wandb = False
device = "cpu"

# PABBO Model Architecture
d_model = 32
n_layers = 3
nhead = 2
dim_feedforward = 64
emb_depth = 2

# LDA Parameters
lda_max_iter = 60
lda_batch_size = 2048
lda_learning_method = "online"

# Optimization
T_bounds = [2, 1000]
iterations = 20
num_runs = 10
base_seed = 42

# Initial Population
pop_size = 20
initial_T_values = [733, 811, 133, 355, 777, 115, 452, 940,
                     879, 345, 576, 153, 950, 602, 162, 238,
                     422, 511, 660, 285]

# GA Hyperparameters
ga_cxpb = 0.9       # crossover probability
ga_mutpb = 0.2      # mutation probability
ga_elite = 5        # elite size

# ES Hyperparameters
es_mu = 5           # number of parents
es_lambda = 10      # number of offspring

# PABBO Hyperparameters
pabbo_exploration_rate = 0.3

# Early Stopping (DISABLED)
early_stop_eps_pct = 0.0
max_no_improvement = 999999
```

---

## Ключевые особенности экспериментальной установки

1. **Честное сравнение**:
   - Все алгоритмы используют одинаковую начальную популяцию
   - Фиксированный бюджет: ровно 20 итераций без early stopping
   - Одинаковые LDA параметры и seeds

2. **Статистическая надежность**:
   - 10 независимых повторений с разными seeds
   - Позволяет оценить не только среднее, но и variance/stability

3. **Воспроизводимость**:
   - Все seeds фиксированы и документированы
   - Initial population сохранена в JSON
   - Полное логирование всех параметров

4. **Полнота данных**:
   - Сохранение не только финальных результатов, но и траекторий
   - Детальные метрики времени
   - История изменения параметров по итерациям

5. **Визуализация**:
   - Множественные форматы (PNG для презентаций, SVG для публикаций)
   - Статистические элементы (error bars, box plots)
   - Как агрегированные, так и индивидуальные графики

---

## Интерпретация результатов для статьи

### Метрики качества
1. **Perplexity**: основная метрика качества
   - Ниже = лучше
   - Сравнивать mean_perplexity и std_perplexity

2. **Convergence speed**: скорость сходимости
   - Анализ по траекториям в history
   - Число итераций до достижения близкого к оптимальному значения

3. **Stability**: стабильность
   - std_perplexity: чем ниже, тем стабильнее
   - Анализ box plots: размер boxes и outliers

### Метрики эффективности
1. **Total time**: общее время оптимизации
   - Важно для практического применения

2. **Time to best**: время до нахождения лучшего решения
   - Может быть меньше total_time
   - Анализ по траекториям с временными метками

### Рекомендуемые таблицы для статьи

**Таблица 1: Основные результаты**
| Dataset | Algorithm | Mean Perplexity | Std | Min | Time (s) |
|---------|-----------|-----------------|-----|-----|----------|
| 20news  | GA        | ...            | ... | ... | ...      |
| 20news  | ES        | ...            | ... | ... | ...      |
| 20news  | PABBO     | ...            | ... | ... | ...      |

**Таблица 2: Статистические тесты**
| Dataset | GA vs ES | GA vs PABBO | ES vs PABBO |
|---------|----------|-------------|-------------|
| 20news  | p-value  | p-value     | p-value     |

---

## Заключение

Данная экспериментальная установка обеспечивает:
- **Объективное** сравнение трех методов оптимизации (GA, ES, PABBO_Full)
- **Статистически значимые** результаты (10 повторений)
- **Воспроизводимые** эксперименты (фиксированные seeds и параметры)
- **Детальную** документацию всех аспектов процесса
- **Визуально привлекательное** представление результатов

Результаты позволяют оценить:
1. Качество оптимизации (perplexity)
2. Вычислительную эффективность (время)
3. Стабильность алгоритмов (variance)
4. Поведение на разных датасетах (generalization)
