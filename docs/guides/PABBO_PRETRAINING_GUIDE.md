# üéì –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—é PABBO Full

–î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –æ–±—É—á–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é Transformer-–º–æ–¥–µ–ª–∏ –¥–ª—è PABBO Full.

---

## üìã –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ](#–∫–∞–∫-—Ä–∞–±–æ—Ç–∞–µ—Ç-–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ)
2. [–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞](#—Å—Ç—Ä—É–∫—Ç—É—Ä–∞-–ø—Ä–æ–µ–∫—Ç–∞)
3. [–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è](#–ø—Ä–æ—Ü–µ—Å—Å-–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è)
4. [–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏](#–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ-–º–æ–¥–µ–ª–∏)
5. [–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏](#–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ-–Ω–∞—Å—Ç—Ä–æ–π–∫–∏)

---

## üß† –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ

### –ö–æ–Ω—Ü–µ–ø—Ü–∏—è

PABBO –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **–∞–º–æ—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é** (amortized optimization):

```python
# –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥: –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
for task in tasks:
    model = train_from_scratch(task)  # –ú–µ–¥–ª–µ–Ω–Ω–æ!

# PABBO: –æ–±—É—á–∞–µ–º –û–î–ù–£ –º–æ–¥–µ–ª—å –Ω–∞ –í–°–ï–• –∑–∞–¥–∞—á–∞—Ö
model = pretrain_on_many_tasks(1000s_of_tasks)  # –ë—ã—Å—Ç—Ä–æ –ø–æ—Ç–æ–º!
for task in new_tasks:
    result = model.predict(task)  # –ú–≥–Ω–æ–≤–µ–Ω–Ω–æ!
```

### –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏

**train.py (line 23)** - –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏:

1. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á** (train.py:144-160)
   - OptimizationSampler —Å–æ–∑–¥–∞–µ—Ç —Å–µ–º–µ–π—Å—Ç–≤–æ —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ GP
   - –î–ª—è GP1D: —Å–ª—É—á–∞–π–Ω—ã–µ 1D —Ñ—É–Ω–∫—Ü–∏–∏ —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≥–ª–æ–±–∞–ª—å–Ω—ã–º –æ–ø—Ç–∏–º—É–º–æ–º
   - data/sampler.py (line 338) - –∫–ª–∞—Å—Å OptimizationSampler

2. **–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–ø–∏–∑–æ–¥–æ–≤** (train.py:208-329)
   - –î–ª—è –∫–∞–∂–¥–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —Å–æ–∑–¥–∞—é—Ç—Å—è –ø–∞—Ä—ã —Ç–æ—á–µ–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
   - –ú–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º: "—Ç–æ—á–∫–∞ A –ª—É—á—à–µ —Ç–æ—á–∫–∏ B"
   - –≠—Ç–æ preference learning - –æ—Å–Ω–æ–≤–∞ PABBO

3. **–û–±—É—á–µ–Ω–∏–µ Transformer** (train.py:339-362)
   - policies/transformer.py (line 55) - –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
   - –ö–æ–¥–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥—É—ç–ª–∏ –∏ –æ—Ü–µ–Ω–æ—á–Ω—ã–µ —Ç–æ—á–∫–∏
   - –ì–æ–ª–æ–≤–∞ af_mlp –≤—ã–¥–∞–µ—Ç –±–∞–ª–ª—ã –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø–∞—Ä (line 196)

4. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤** (train.py:486-509)
   - **–í–ê–ñ–ù–û**: –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ `results/PABBO/{expid}/ckpt.tar`
   - –ù–ï –≤ `policies/checkpoints/`!

---

## üìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

### –ü–∞–ø–∫–∏ –∏ —Ñ–∞–π–ª—ã

```
pabbo_method/
‚îú‚îÄ‚îÄ train.py                    # –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ evaluate_continuous.py      # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ train.yaml             # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ train_rastrigin1d_test.yaml  # –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç (10-20 –º–∏–Ω)
‚îÇ   ‚îî‚îÄ‚îÄ evaluate.yaml          # –ö–æ–Ω—Ñ–∏–≥ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ sampler.py             # OptimizationSampler (line 338)
‚îÇ   ‚îî‚îÄ‚îÄ function.py            # –¢–µ—Å—Ç–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (line 27)
‚îú‚îÄ‚îÄ policies/
‚îÇ   ‚îî‚îÄ‚îÄ transformer.py         # TransformerModel (line 55)
‚îú‚îÄ‚îÄ results/                   # ‚Üê –°–û–ó–î–ê–ï–¢–°–Ø –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò
‚îÇ   ‚îî‚îÄ‚îÄ PABBO/
‚îÇ       ‚îî‚îÄ‚îÄ {expid}/
‚îÇ           ‚îî‚îÄ‚îÄ ckpt.tar       # ‚Üê –ú–û–î–ï–õ–¨ –ó–î–ï–°–¨!
‚îî‚îÄ‚îÄ datasets/                  # ‚Üê –°–û–ó–î–ê–ï–¢–°–Ø –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò
    ‚îî‚îÄ‚îÄ evaluation/
```

### –ì–¥–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –º–æ–¥–µ–ª–∏

**–í–ê–ñ–ù–û**: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è —Ç–∞–∫:

```python
# train.py (line 26-28)
exp_path = results/PABBO/{expid}/
model_path = exp_path/ckpt.tar

# –ù–∞–ø—Ä–∏–º–µ—Ä:
# results/PABBO/PABBO_rastrigin1d_test_quick_20241103_190000/ckpt.tar
```

**expid** —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ (configs/train.yaml:20):
```yaml
expid: ${experiment.model}_${data.name}_${now:%Y%m%d_%H%M%S}
```

---

## üöÄ –ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è

### –®–∞–≥ 1: –ë—ã—Å—Ç—Ä–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (10-20 –º–∏–Ω—É—Ç)

–î–ª—è –Ω–∞—á–∞–ª–∞ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç:

```bash
cd pabbo_method

# –ó–∞–ø—É—Å–∫–∞–µ–º –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ
python train.py --config-name=train_rastrigin1d_test

# –ß—Ç–æ –≤—ã —É–≤–∏–¥–∏—Ç–µ:
# - –°–æ–∑–¥–∞–µ—Ç—Å—è –ø–∞–ø–∫–∞ results/
# - –ö–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤ –ø–µ—á–∞—Ç–∞–µ—Ç—Å—è –ø—Ä–æ–≥—Ä–µ—Å—Å
# - –ö–∞–∂–¥—ã–µ 500 —à–∞–≥–æ–≤ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è —á–µ–∫–ø–æ–∏–Ω—Ç
```

**–í—ã–≤–æ–¥ –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–∞–∫:**

```
Experiment: PABBO_rastrigin1d_test_quick_20241103_190000
Total number of parameters: 125432

PABBO_rastrigin1d_test_quick step 100 lr 1.000e-03 [train_loss]
    loss 0.5234 cls_loss 0.5234 policy_loss 0.0000 acc 0.6543 kt_cor 0.4321

PABBO_rastrigin1d_test_quick step 500 lr 9.239e-04 [train_loss]
    loss 0.2145 cls_loss 0.2145 policy_loss 0.0000 acc 0.8234 kt_cor 0.7123

PABBO_rastrigin1d_test_quick step 1000 lr 7.071e-04 [train_loss]
    loss 0.1543 cls_loss 0.1543 policy_loss 0.0000 acc 0.8876 kt_cor 0.8234
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞** (configs/train_rastrigin1d_test.yaml):
- `n_steps: 2000` - –≤—Å–µ–≥–æ —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è
- `n_burnin: 800` - –ø–µ—Ä–≤—ã–µ 800 —à–∞–≥–æ–≤ —Ç–æ–ª—å–∫–æ prediction task
- `train_batch_size: 64` - —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è prediction
- `ac_train_batch_size: 8` - —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è acquisition
- `model.d_model: 32` - —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ (–º–∞–ª–µ–Ω—å–∫–∞—è)
- `model.n_layers: 3` - —Å–ª–æ—ë–≤ Transformer

### –®–∞–≥ 2: –ù–∞–π—Ç–∏ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å

```bash
# –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
ls -la results/PABBO/

# –í—ã —É–≤–∏–¥–∏—Ç–µ –ø–∞–ø–∫—É —Å –∏–º–µ–Ω–µ–º —Ç–∏–ø–∞:
# PABBO_rastrigin1d_test_quick_20241103_190000/

# –ú–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∑–¥–µ—Å—å:
ls -la results/PABBO/PABBO_rastrigin1d_test_quick_20241103_190000/ckpt.tar

# –≠—Ç–æ –∏ –µ—Å—Ç—å –≤–∞—à–∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å!
```

### –®–∞–≥ 3: –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)

–î–ª—è production —Å–æ–∑–¥–∞–π—Ç–µ —Å–≤–æ—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é:

```bash
# –°–æ–∑–¥–∞–π—Ç–µ pabbo_method/configs/train_gp1d_full.yaml
cd pabbo_method

python train.py --config-name=train \
  experiment.expid=PABBO_GP1D_FULL \
  experiment.device=cpu \
  experiment.wandb=false \
  data.name=GP1D \
  data.d_x=1 \
  data.x_range="[[-1,1]]" \
  data.min_num_ctx=1 \
  data.max_num_ctx=50 \
  train.n_steps=8000 \
  train.n_burnin=3000 \
  train.train_batch_size=128 \
  train.ac_train_batch_size=16 \
  model.d_model=64 \
  model.n_layers=6 \
  model.nhead=4
```

**–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:**
- CPU: ~1-2 —á–∞—Å–∞
- GPU (cuda): ~20-30 –º–∏–Ω—É—Ç

**–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è –≤:**
```
results/PABBO/PABBO_GP1D_FULL/ckpt.tar
```

### –®–∞–≥ 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏

```bash
cd pabbo_method

# –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –≤–∞—à–µ–π –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
python evaluate_continuous.py --config-name=evaluate \
  experiment.model=PABBO \
  experiment.expid=PABBO_rastrigin1d_test_quick_20241103_190000 \
  experiment.device=cpu \
  experiment.wandb=false \
  data.name=rastrigin1D \
  data.d_x=1 \
  data.x_range="[[-5.12,5.12]]" \
  data.Xopt="[[0.0]]" \
  data.yopt="[[0.0]]" \
  eval.eval_max_T=60 \
  eval.eval_num_query_points=256
```

**–ß—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è:**

evaluate_continuous.py (line 28):
1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ `results/PABBO/{expid}/ckpt.tar` (line 44)
2. –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–∞ –Ω–æ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏—è—Ö
3. –°—á–∏—Ç–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏: regret, entropy, correlation
4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ `results/evaluation/{data.name}/{model}/{expid}/`

---

## üîß –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

### –í lda_hyperopt (PABBO_FULL)

**–í–ê–ñ–ù–û**: –£–∫–∞–∂–∏—Ç–µ –ü–û–õ–ù–´–ô –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏!

```bash
cd lda_hyperopt

# –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à expid –∏–∑ train.py
EXPID="PABBO_rastrigin1d_test_quick_20241103_190000"
MODEL_PATH="../pabbo_method/results/PABBO/${EXPID}/ckpt.tar"

python run.py \
  --data data.npz \
  --algorithms PABBO_Full \
  --pabbo-model "${MODEL_PATH}" \
  --iterations 50 \
  --seed 42
```

### –ö–∞–∫ PABBO_FULL –∑–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å

lda_hyperopt/optimizers/pabbo_full.py (line 140-163):

```python
def _load_model(self, model_path: str):
    """Load trained Transformer model."""
    checkpoint = torch.load(model_path, map_location='cpu')

    # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∫–æ–Ω—Ñ–∏–≥ –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
    if 'config' in checkpoint:
        config = checkpoint['config']
        self.model = TransformerModel(**config)
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥
        self.model = TransformerModel(
            d_model=64,
            n_heads=8,
            n_layers=6,
            dropout=0.1
        )

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
    if 'model' in checkpoint:
        self.model.load_state_dict(checkpoint['model'])
    else:
        self.model.load_state_dict(checkpoint)
```

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞** (train.py:491-497):

```python
ckpt = {
    "model": model_state_dict,      # –í–µ—Å–∞ –º–æ–¥–µ–ª–∏
    "optimizer": optimizer.state_dict(),
    "scheduler": scheduler.state_dict(),
    "expdir": expdir,
    "step": epoch + 1,
}
```

---

## ‚öôÔ∏è –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏

–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è LDA –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:

#### 1. –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω T

```python
# –í –≤–∞—à–µ–π –∑–∞–¥–∞—á–µ:
T_bounds = (2, 1000)  # –ù–∞–ø—Ä–∏–º–µ—Ä

# –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ [-1, 1]:
x_range = [[-1, 1]]
```

#### 2. –°–æ–∑–¥–∞–π—Ç–µ –∫–∞—Å—Ç–æ–º–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é

```yaml
# pabbo_method/configs/train_lda_optimized.yaml

data:
  name: "GP1D_LDA"
  d_x: 1
  x_range: [[-1, 1]]  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
  min_num_ctx: 5
  max_num_ctx: 100   # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è LDA (–±–æ–ª—å—à–µ –∏—Å—Ç–æ—Ä–∏–∏)

experiment:
  expid: PABBO_LDA_OPTIMIZED
  device: cuda  # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω

train:
  n_steps: 15000     # –ë–æ–ª—å—à–µ —à–∞–≥–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
  n_burnin: 5000
  train_batch_size: 128
  ac_train_batch_size: 16
  max_T: 100         # –£–≤–µ–ª–∏—á–µ–Ω–æ (–±–æ–ª—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π)

model:
  d_model: 128       # –ë–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å
  n_layers: 8
  nhead: 8
  dim_feedforward: 256
```

#### 3. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å

```bash
cd pabbo_method
python train.py --config-name=train_lda_optimized
```

### –ü–æ–Ω–∏–º–∞–Ω–∏–µ –¥–≤—É—Ö—Ñ–∞–∑–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

train.py –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–≤–µ —Ñ–∞–∑—ã (line 208-329):

#### –§–∞–∑–∞ 1: Burnin (—à–∞–≥–∏ 1-n_burnin)

```python
# train.py (line 213-228)
if epoch <= n_burnin:
    # –¢–æ–ª—å–∫–æ prediction task
    # –ú–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –ø–æ –ø–∞—Ä–∞–º
    X_pred, y_pred = sampler.sample(...)

    # Compute BCE loss –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π
    cls_loss = preference_cls_loss(f=pred_tar_f, c=src_c)
```

**–¶–µ–ª—å**: –ù–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –ø–æ–Ω–∏–º–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ –ø–∞—Ä–Ω—ã–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.

#### –§–∞–∑–∞ 2: Acquisition Learning (—à–∞–≥–∏ n_burnin+1 –¥–æ n_steps)

```python
# train.py (line 229-412)
else:
    # Prediction + Acquisition task
    X_pred, y_pred = sampler.sample(...)  # –¥–ª—è prediction
    X_ac, y_ac = sampler.sample(...)      # –¥–ª—è acquisition

    # Policy learning loop (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ max_T —à–∞–≥–æ–≤)
    for t in range(1, max_T + 1):
        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é –ø–∞—Ä—É —Ç–æ—á–µ–∫
        acq_values, next_pair = action(model, context_pairs, ...)

        # –ü–æ–ª—É—á–∞–µ–º reward
        reward = get_reward(context_pairs_y, acq_values, ...)

    # –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ policy gradient
    policy_loss = finish_episode(rewards, log_probs, ...)
    loss = policy_loss + loss_weight * cls_loss
```

**–¶–µ–ª—å**: –ù–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –≤—ã–±–∏—Ä–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞.

### –í–∞–∂–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ë—ã—Å—Ç—Ä–æ | –ë–∞–ª–∞–Ω—Å | –ö–∞—á–µ—Å—Ç–≤–æ | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|--------|--------|----------|----------|
| `n_steps` | 2000 | 8000 | 20000 | –®–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è |
| `n_burnin` | 800 | 3000 | 7000 | –®–∞–≥–æ–≤ –≤ —Ñ–∞–∑–µ 1 |
| `d_model` | 32 | 64 | 128 | –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ |
| `n_layers` | 3 | 6 | 8-12 | –°–ª–æ—ë–≤ Transformer |
| `nhead` | 2 | 4 | 8 | –ì–æ–ª–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è |
| `max_T` | 30 | 64 | 100 | –®–∞–≥–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ |
| `train_batch_size` | 64 | 128 | 256 | –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (—Ñ–∞–∑–∞ 1) |
| `ac_train_batch_size` | 8 | 16 | 32 | –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (—Ñ–∞–∑–∞ 2) |

---

## üéØ –ö—É–¥–∞ –∫–ª–∞—Å—Ç—å –º–æ–¥–µ–ª—å

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–∑ results/ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤:
pabbo_method/results/PABBO/{expid}/ckpt.tar

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é:
cd lda_hyperopt
python run.py \
  --data data.npz \
  --algorithms PABBO_Full \
  --pabbo-model ../pabbo_method/results/PABBO/PABBO_GP1D_FULL/ckpt.tar
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–∞–ø–∫—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

```bash
# –°–æ–∑–¥–∞–π—Ç–µ –ø–∞–ø–∫—É –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω –º–æ–¥–µ–ª–µ–π
mkdir -p pabbo_method/trained_models

# –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
cp results/PABBO/PABBO_GP1D_FULL/ckpt.tar \
   trained_models/pabbo_gp1d_production.tar

# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ
cd lda_hyperopt
python run.py \
  --data data.npz \
  --algorithms PABBO_Full \
  --pabbo-model ../pabbo_method/trained_models/pabbo_gp1d_production.tar
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

**1. Classification Loss (cls_loss)**
- –ù–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
- –î–æ–ª–∂–Ω–∞ —É–º–µ–Ω—å—à–∞—Ç—å—Å—è: 0.7 ‚Üí 0.3 ‚Üí 0.1
- train.py (line 349-352)

**2. Accuracy (acc)**
- –¢–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π
- –î–æ–ª–∂–Ω–∞ —Ä–∞—Å—Ç–∏: 0.5 ‚Üí 0.7 ‚Üí 0.85+
- train.py (line 355)

**3. Kendall Tau Correlation (kt_cor)**
- –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å –∏—Å—Ç–∏–Ω–Ω—ã–º–∏
- –î–æ–ª–∂–Ω–∞ —Ä–∞—Å—Ç–∏: 0.3 ‚Üí 0.6 ‚Üí 0.8+
- train.py (line 356-360)

**4. Policy Loss (–ø–æ—Å–ª–µ burnin)**
- –ü–æ—Ç–µ—Ä—è reinforcement learning
- –î–æ–ª–∂–Ω–∞ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è
- train.py (line 431-437)

**5. Final Simple Regret**
- –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–º –æ–ø—Ç–∏–º—É–º–æ–º
- –î–æ–ª–∂–Ω–∞ —É–º–µ–Ω—å—à–∞—Ç—å—Å—è
- train.py (line 428)

### –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ö–æ—Ä–æ—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è

```
# –í –Ω–∞—á–∞–ª–µ
step 100 | loss 0.6543 | cls_loss 0.6543 | acc 0.5234 | kt_cor 0.2156

# –ü–æ—Å–ª–µ burnin
step 800 | loss 0.2345 | cls_loss 0.2345 | acc 0.7823 | kt_cor 0.6543

# –ù–∞—á–∞–ª–æ acquisition learning
step 801 | loss 0.3456 | cls_loss 0.2123 | policy_loss 0.1333 | acc 0.8012

# –í –∫–æ–Ω—Ü–µ
step 8000 | loss 0.1234 | cls_loss 0.0876 | policy_loss 0.0358 | acc 0.9234 | kt_cor 0.8765
```

**–•–æ—Ä–æ—à–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:**
- ‚úÖ cls_loss < 0.2
- ‚úÖ acc > 0.85
- ‚úÖ kt_cor > 0.75
- ‚úÖ final_simple_regret < 0.1

---

## üêõ Troubleshooting

### Loss –Ω–µ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è

```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ learning rate
python train.py --config-name=train_rastrigin1d_test \
  train.lr=1e-4 \
  train.ac_lr=1e-5
```

### Out of Memory

```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä—ã
python train.py --config-name=train_rastrigin1d_test \
  train.train_batch_size=32 \
  train.ac_train_batch_size=4 \
  model.d_model=32 \
  model.n_layers=3
```

### –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –≤ PABBO_FULL

**–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å:**
```bash
# –ù–∞–π–¥–∏—Ç–µ –≤—Å–µ –º–æ–¥–µ–ª–∏
find pabbo_method/results -name "ckpt.tar"

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ–∞–π–ª —á–∏—Ç–∞–µ—Ç—Å—è
python -c "import torch; print(torch.load('path/to/ckpt.tar', map_location='cpu').keys())"
```

**–î–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å:**
```python
dict_keys(['model', 'optimizer', 'scheduler', 'expdir', 'step'])
```

---

## üìù –ü–æ—à–∞–≥–æ–≤—ã–π —á–µ–∫–ª–∏—Å—Ç

### –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è

- [ ] 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: `pip install torch botorch gpytorch hydra-core`
- [ ] 2. –ü–µ—Ä–µ–π—Ç–∏ –≤ –ø–∞–ø–∫—É: `cd pabbo_method`
- [ ] 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å –±—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç: `python train.py --config-name=train_rastrigin1d_test`
- [ ] 4. –î–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (~10-20 –º–∏–Ω)
- [ ] 5. –ù–∞–π—Ç–∏ –º–æ–¥–µ–ª—å: `ls -la results/PABBO/*/ckpt.tar`
- [ ] 6. –ó–∞–ø–∏—Å–∞—Ç—å –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
- [ ] 7. (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ó–∞–ø—É—Å—Ç–∏—Ç—å evaluate –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
- [ ] 8. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ lda_hyperopt —Å —Ñ–ª–∞–≥–æ–º `--pabbo-model {–ø—É—Ç—å}`

### –î–ª—è production

- [ ] 1. –°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (—Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å train.yaml)
- [ ] 2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥ –∑–∞–¥–∞—á—É
- [ ] 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å GPU: `device=cuda`
- [ ] 4. –£–≤–µ–ª–∏—á–∏—Ç—å —à–∞–≥–∏: `n_steps=15000`
- [ ] 5. –£–≤–µ–ª–∏—á–∏—Ç—å –º–æ–¥–µ–ª—å: `d_model=128`, `n_layers=8`
- [ ] 6. –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
- [ ] 7. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–∞–ø–∫—É
- [ ] 8. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

---

## üéì –¢–µ–æ—Ä–∏—è: –ø–æ—á–µ–º—É —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç

### Preference-based Optimization

PABBO –Ω–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞–ø—Ä—è–º—É—é, –∞ —É—á–∏—Ç—Å—è –Ω–∞ **—Å—Ä–∞–≤–Ω–µ–Ω–∏—è—Ö**:

```python
# –í–º–µ—Å—Ç–æ:
f(x1) = 2.5, f(x2) = 3.7  # –ù—É–∂–Ω—ã —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

# PABBO –∏—Å–ø–æ–ª—å–∑—É–µ—Ç:
f(x1) < f(x2)  # –¢–æ–ª—å–∫–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ!
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
1. –†–∞–±–æ—Ç–∞–µ—Ç –¥–∞–∂–µ –∫–æ–≥–¥–∞ —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞—à—É–º–ª–µ–Ω—ã
2. Robustness –∫ –º–∞—Å—à—Ç–∞–±—É —Ñ—É–Ω–∫—Ü–∏–∏
3. –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞-—ç–∫—Å–ø–µ—Ä—Ç–∞

### Amortized Optimization

```python
# –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π BO:
for task in tasks:
    gp = train_gp(task)       # 100 –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    optimize(gp)              # 50 –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    # –ò—Ç–æ–≥–æ: 150 √ó N –∑–∞–¥–∞—á

# PABBO:
model = pretrain(1000_tasks)   # –î–µ–ª–∞–µ–º –û–î–ò–ù —Ä–∞–∑
for task in tasks:
    optimize(model)            # 50 –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    # –ò—Ç–æ–≥–æ: –ø—Ä–µ—Ç—Ä–µ–π–Ω + 50 √ó N –∑–∞–¥–∞—á
```

–ï—Å–ª–∏ –∑–∞–¥–∞—á –º–Ω–æ–≥–æ (N > 20), PABBO **–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ**.

### Transformer Architecture

policies/transformer.py (line 55-100):

```python
# –ö–∞–∂–¥–∞—è –ø–∞—Ä–∞ —Ç–æ—á–µ–∫ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ç–æ–∫–µ–Ω–æ–º
token = embed([x1, x2, preference])

# Transformer –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤
context = [token_1, token_2, ..., token_t]
representation = Transformer(context)

# –ì–æ–ª–æ–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç acquisition value –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä
scores = af_mlp(representation)  # (line 196)
```

**–ü–æ—á–µ–º—É Transformer?**
1. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
2. Attention –º–µ—Ö–∞–Ω–∏–∑–º —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –≤–∞–∂–Ω—ã—Ö –ø–∞—Ä–∞—Ö
3. –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –±–æ–ª—å—à–∏–µ –∏—Å—Ç–æ—Ä–∏–∏

---

## üöÄ –ì–æ—Ç–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è –∫–æ–ø–∏–ø–∞—Å—Ç–∞

```bash
#!/bin/bash
# –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è PABBO

# 1. –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
cd pabbo_method
python train.py --config-name=train_rastrigin1d_test

# 2. –ù–∞–π—Ç–∏ –º–æ–¥–µ–ª—å
EXPID=$(ls -t results/PABBO/ | head -1)
echo "–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞: results/PABBO/${EXPID}/ckpt.tar"

# 3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å
python evaluate_continuous.py --config-name=evaluate \
  experiment.model=PABBO \
  experiment.expid="${EXPID}" \
  experiment.device=cpu \
  experiment.wandb=false \
  data.name=rastrigin1D \
  data.d_x=1 \
  data.x_range="[[-5.12,5.12]]" \
  data.Xopt="[[0.0]]" \
  data.yopt="[[0.0]]"

# 4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ LDA
cd ../lda_hyperopt
python run.py \
  --data data.npz \
  --algorithms PABBO_Full \
  --pabbo-model "../pabbo_method/results/PABBO/${EXPID}/ckpt.tar" \
  --iterations 50
```

---

**–ì–æ—Ç–æ–≤–æ!** –¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å –ø–æ–ª–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è PABBO. üéâ

–ù–∞—á–Ω–∏—Ç–µ —Å –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç, –∑–∞—Ç–µ–º –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ –ø–æ–ª–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é.