# üéì –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –æ–±—É—á–µ–Ω–∏—é PABBO Transformer

–ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–∏ PABBO –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ LDA.

---

## üìã –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [–ß—Ç–æ —Ç–∞–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ PABBO?](#—á—Ç–æ-—Ç–∞–∫–æ–µ-–æ–±—É—á–µ–Ω–∏–µ-pabbo)
2. [–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (10 –º–∏–Ω—É—Ç)](#–±—ã—Å—Ç—Ä—ã–π-—Å—Ç–∞—Ä—Ç)
3. [–ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (30-60 –º–∏–Ω—É—Ç)](#–ø–æ–ª–Ω–æ–µ-–æ–±—É—á–µ–Ω–∏–µ)
4. [–û–±—É—á–µ–Ω–∏–µ –¥–ª—è LDA](#–æ–±—É—á–µ–Ω–∏–µ-–¥–ª—è-lda)
5. [–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–Ω—É—Ç—Ä–∏](#–∫–∞–∫-—ç—Ç–æ-—Ä–∞–±–æ—Ç–∞–µ—Ç-–≤–Ω—É—Ç—Ä–∏)
6. [–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è](#–∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è)
7. [Troubleshooting](#troubleshooting)

---

## ü§î –ß—Ç–æ —Ç–∞–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ PABBO?

**PABBO (Preference-Augmented Black-Box Optimization)** - —ç—Ç–æ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å (Transformer), –∫–æ—Ç–æ—Ä–∞—è —É—á–∏—Ç—Å—è **–∫–∞–∫ –∏—Å–∫–∞—Ç—å –º–∏–Ω–∏–º—É–º —Ñ—É–Ω–∫—Ü–∏–∏**.

### –ü—Ä–æ—Å—Ç–∞—è –∞–Ω–∞–ª–æ–≥–∏—è

**–û–±—ã—á–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (GA, ES):**
- –ö–∞–∂–¥—ã–π —Ä–∞–∑ –Ω–∞—á–∏–Ω–∞–µ–º "—Å –Ω—É–ª—è"
- –ù–µ –ø–æ–º–Ω–∏–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ–ø—ã—Ç
- –ö–∞–∫ –Ω–æ–≤–∏—á–æ–∫ —Ä–µ—à–∞–µ—Ç –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É

**PABBO –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:**
- –ü–æ–º–Ω–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —Å–æ—Ç–µ–Ω –∑–∞–¥–∞—á
- "–í–∏–¥–µ–ª —Ç–∞–∫–æ–µ —Ä–∞–Ω—å—à–µ, –∑–Ω–∞—é —á—Ç–æ –¥–µ–ª–∞—Ç—å"
- –ö–∞–∫ —ç–∫—Å–ø–µ—Ä—Ç —Ä–µ—à–∞–µ—Ç –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É

### –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏?

1. **–ì–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Ç—ã—Å—è—á–∏ –∑–∞–¥–∞—á –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏** (—Ä–∞–∑–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏)
2. **–ú–æ–¥–µ–ª—å –ø—Ä–æ–±—É–µ—Ç –∏—Ö —Ä–µ—à–∞—Ç—å**
3. **–£—á–∏—Ç—Å—è –Ω–∞ –æ—à–∏–±–∫–∞—Ö** (preference learning)
4. **–ó–∞–ø–æ–º–∏–Ω–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã** —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç **–±—ã—Å—Ç—Ä–µ–µ –Ω–∞—Ö–æ–¥–∏—Ç—å –º–∏–Ω–∏–º—É–º** –Ω–æ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π.

---

## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (10 –º–∏–Ω—É—Ç)

### –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
cd /Users/draiqws/Llabs/pabbo_method

# –ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç PyTorch
pip install torch torchvision torchaudio

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install botorch gpytorch hydra-core
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏:**
```bash
python -c "import torch; import botorch; print('OK!')"
```

### –®–∞–≥ 2: –ë—ã—Å—Ç—Ä–æ–µ —Ç–µ—Å—Ç–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ

```bash
# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ 2000 —à–∞–≥–æ–≤ (~10 –º–∏–Ω—É—Ç)
python train.py --config-name train_rastrigin1d_test

# –í—ã —É–≤–∏–¥–∏—Ç–µ:
# Step 0/2000 | Loss: 0.6931 | Best: 2.456
# Step 100/2000 | Loss: 0.4521 | Best: 1.234
# ...
# Training complete! Model saved to: policies/checkpoints/model_best.pt
```

### –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏

```bash
# –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
python evaluate_continuous.py \
  --model policies/checkpoints/model_best.pt \
  --function rastrigin \
  --n_trials 10 \
  --budget 50

# –†–µ–∑—É–ª—å—Ç–∞—Ç:
# Mean best value: 0.45 ¬± 0.18
# Success rate: 90%
```

### –®–∞–≥ 4: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ LDA

```bash
cd ../lda_hyperopt

# –ó–∞–ø—É—Å–∫ —Å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
python run.py \
  --data data/val_bow.npz \
  --algorithms PABBO_Full \
  --pabbo-model ../pabbo_method/policies/checkpoints/model_best.pt \
  --iterations 50 \
  --outdir results_pabbo_full
```

‚úÖ **–ì–æ—Ç–æ–≤–æ!** –¢–µ–ø–µ—Ä—å PABBO_Full –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å.

---

## üéØ –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (30-60 –º–∏–Ω—É—Ç)

–î–ª—è **–ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ:

```bash
cd pabbo_method

# –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (8000 —à–∞–≥–æ–≤)
python train.py --config-name train_rastrigin1d
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–ª–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:**
- **–®–∞–≥–æ–≤**: 8000 (vs 2000 –≤ –±—ã—Å—Ç—Ä–æ–º)
- **–ú–æ–¥–µ–ª—å**: d_model=64, 6 layers (vs 32, 3 layers)
- **–í—Ä–µ–º—è**: ~30-60 –º–∏–Ω—É—Ç (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç CPU/GPU)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- –õ—É—á—à–µ –æ–±–æ–±—â–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
- –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å
- –í—ã—à–µ success rate

---

## üî¨ –û–±—É—á–µ–Ω–∏–µ –¥–ª—è LDA (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

–î–ª—è **–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ LDA** –Ω—É–∂–Ω–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ **–¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏—è—Ö** (T - —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ).

### –í–∞—Ä–∏–∞–Ω—Ç 1: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ—Ö–æ–∂–∏—Ö —Ñ—É–Ω–∫—Ü–∏—è—Ö

```bash
# –û–±—É—á–∞–µ–º –Ω–∞ –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–π –≤–µ—Ä—Å–∏–∏ Rastrigin
python train.py --config-name train_discrete

# –í config –Ω—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å:
# - discrete: true
# - bounds: [2, 1000]  # –∫–∞–∫ –≤ LDA
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö LDA –∑–∞–¥–∞—á–∞—Ö

–°–æ–∑–¥–∞–π—Ç–µ `configs/train_lda_synthetic.yaml`:

```yaml
seed: 42
function: lda_synthetic  # –ù—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ data/function.py
n_steps: 8000
batch_size: 16

# –î–∏—Å–∫—Ä–µ—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∫–∞–∫ –≤ LDA
discrete: true
bounds:
  T_min: 2
  T_max: 1000

model:
  d_model: 64
  n_heads: 8
  n_layers: 6
  dropout: 0.1

optimizer:
  type: adam
  lr: 1e-4
  weight_decay: 1e-5

training:
  n_episodes: 100
  budget: 20
  warmup_steps: 100
```

–ó–∞–ø—É—Å–∫:
```bash
python train.py --config-name train_lda_synthetic
```

### –í–∞—Ä–∏–∞–Ω—Ç 3: Multi-task –æ–±—É—á–µ–Ω–∏–µ

–û–±—É—á–µ–Ω–∏–µ –Ω–∞ **–Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏—è—Ö** –¥–ª—è –ª—É—á—à–µ–π generalization:

```bash
# –û–±—É—á–∞–µ–º –Ω–∞ —Å–º–µ—Å–∏ —Ñ—É–Ω–∫—Ü–∏–π
python train.py \
  --config-name train_multitask \
  functions=[rastrigin1D,forrester1D,sinexp1D] \
  n_steps=10000
```

---

## üîç –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–Ω—É—Ç—Ä–∏

### –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è (–ø–æ—à–∞–≥–æ–≤–æ)

#### –®–∞–≥ 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–ø–∏–∑–æ–¥–∞

```python
# 1. –°–æ–∑–¥–∞–µ—Ç—Å—è —Å–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–∞—á–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
function = Rastrigin1D()

# 2. –ù–∞—á–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞
x_init = random.uniform(-5, 5)
history = [(x_init, function(x_init))]

# 3. –¶–∏–∫–ª –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (20 —à–∞–≥–æ–≤)
for step in range(20):
    # –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â—É—é —Ç–æ—á–∫—É
    x_next = policy(history)  # Transformer!

    # –û—Ü–µ–Ω–∫–∞
    y_next = function(x_next)

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
    history.append((x_next, y_next))
```

#### –®–∞–≥ 2: Preference Learning

```python
# –ò–∑ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–∑–¥–∞—é—Ç—Å—è –ø–∞—Ä—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
pairs = []
for i in range(len(history)):
    for j in range(i+1, len(history)):
        x_i, y_i = history[i]
        x_j, y_j = history[j]

        # –ï—Å–ª–∏ y_i –ª—É—á—à–µ (–º–µ–Ω—å—à–µ)
        if y_i < y_j:
            pairs.append((x_i, x_j, label=1))  # x_i > x_j
        else:
            pairs.append((x_j, x_i, label=1))  # x_j > x_i
```

#### –®–∞–≥ 3: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

```python
# Loss: –Ω–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞—Ç—å
for (x_better, x_worse, _) in pairs:
    score_better = policy.score(x_better, history)
    score_worse = policy.score(x_worse, history)

    # Preference loss
    loss = -log(sigmoid(score_better - score_worse))

    # Backpropagation
    loss.backward()

optimizer.step()
```

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Transformer

```
Input: [(x‚ÇÅ, y‚ÇÅ), (x‚ÇÇ, y‚ÇÇ), ..., (x‚Çô, y‚Çô)]
   ‚Üì
[Embedding Layer]
   x, y ‚Üí d_model —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
   ‚Üì
[Positional Encoding]
   –î–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Ä—è–¥–∫–µ
   ‚Üì
[Transformer Encoder]
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Self-Attention  ‚îÇ ‚Üê –ö–∞–∫–∏–µ —Ç–æ—á–∫–∏ –≤–∞–∂–Ω—ã?
   ‚îÇ Feed-Forward    ‚îÇ
   ‚îÇ LayerNorm       ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   √ó 6 layers
   ‚Üì
[Output Head]
   Linear ‚Üí score –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏
   ‚Üì
Output: Scores –∏–ª–∏ Next candidate x‚Çô‚Çä‚ÇÅ
```

**–ß—Ç–æ —É—á–∏—Ç –º–æ–¥–µ–ª—å:**
- –ö–∞–∫–∏–µ —Ä–µ–≥–∏–æ–Ω—ã –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã
- –ö–∞–∫ –±–∞–ª–∞–Ω—Å exploration/exploitation
- –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π

---

## üõ† –ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è

### 1. –ò–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏

**–ú–∞–ª–µ–Ω—å–∫–∞—è –º–æ–¥–µ–ª—å (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ —Ö—É–∂–µ):**
```bash
python train.py \
  --config-name train_rastrigin1d_test \
  model.d_model=32 \
  model.n_layers=3 \
  model.n_heads=4
```

**–ë–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –ª—É—á—à–µ):**
```bash
python train.py \
  --config-name train_rastrigin1d \
  model.d_model=128 \
  model.n_layers=8 \
  model.n_heads=8
```

### 2. –ò–∑–º–µ–Ω–∏—Ç—å learning rate

```bash
# –ë—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–æ–∂–µ—Ç diverge
python train.py --config-name train_rastrigin1d lr=1e-3

# –ú–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ
python train.py --config-name train_rastrigin1d lr=1e-5
```

### 3. –ò–∑–º–µ–Ω–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤

```bash
# –ö–æ—Ä–æ—Ç–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ (—Ç–µ—Å—Ç)
python train.py --config-name train_rastrigin1d n_steps=1000

# –î–ª–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (production)
python train.py --config-name train_rastrigin1d n_steps=20000
```

### 4. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–≤–æ–µ–π —Ñ—É–Ω–∫—Ü–∏–∏

–°–æ–∑–¥–∞–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –≤ `data/function.py`:

```python
def my_lda_like_function(x: torch.Tensor, negate: bool = True, add_dim: bool = True):
    """
    –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ö–æ–∂–∞—è –Ω–∞ LDA perplexity.

    Args:
        x: Input tensor (shape: [batch, dim])
        negate: If True, return -f(x)
        add_dim: If True, add output dimension

    Returns:
        Function values
    """
    # –í–∞—à–∞ —Ñ—É–Ω–∫—Ü–∏—è –∑–¥–µ—Å—å
    # –ù–∞–ø—Ä–∏–º–µ—Ä: —Å–∏–º—É–ª—è—Ü–∏—è LDA perplexity
    T = x.squeeze(-1)  # T –∏–∑ [2, 1000]

    # –°–∏–º—É–ª—è—Ü–∏—è: perplexity —Ä–∞—Å—Ç–µ—Ç –¥–ª—è –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏—Ö/–±–æ–ª—å—à–∏—Ö T
    y = 1000 / T + T / 10 + 100 * torch.sin(T / 50)

    if negate:
        y = -y

    if add_dim:
        y = y.unsqueeze(-1)

    return y
```

–ó–∞—Ç–µ–º –≤ config:
```yaml
function: my_lda_like_function
discrete: true
bounds:
  T_min: 2
  T_max: 1000
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

### Console output

```
[2024-11-03 10:00:00] Starting training...
[2024-11-03 10:00:00] Config: train_rastrigin1d_test
[2024-11-03 10:00:00] Model: d_model=32, n_layers=3, n_heads=4
[2024-11-03 10:00:00] Device: cpu

Step 0/2000 | Loss: 0.6931 | Best: 2.456 | Time: 0.12s
Step 100/2000 | Loss: 0.4521 | Best: 1.234 | Time: 12.5s
Step 200/2000 | Loss: 0.3215 | Best: 0.876 | Time: 24.8s
...
Step 2000/2000 | Loss: 0.1234 | Best: 0.245 | Time: 250s

Training complete!
Best model saved to: policies/checkpoints/model_best.pt
Final checkpoint: policies/checkpoints/model_step_2000.pt
```

### –ß—Ç–æ –æ–∑–Ω–∞—á–∞—é—Ç –º–µ—Ç—Ä–∏–∫–∏?

- **Loss**: Preference loss (–¥–æ–ª–∂–Ω–∞ —É–º–µ–Ω—å—à–∞—Ç—å—Å—è)
  - –ù–∞—á–∞–ª–æ: ~0.69 (—Å–ª—É—á–∞–π–Ω–∞—è –º–æ–¥–µ–ª—å)
  - –ö–æ–Ω–µ—Ü: ~0.1-0.2 (—Ö–æ—Ä–æ—à–æ –æ–±—É—á–µ–Ω–Ω–∞—è)

- **Best**: –õ—É—á—à–µ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
  - –î–æ–ª–∂–Ω–æ –ø—Ä–∏–±–ª–∏–∂–∞—Ç—å—Å—è –∫ –≥–ª–æ–±–∞–ª—å–Ω–æ–º—É –º–∏–Ω–∏–º—É–º—É
  - –î–ª—è Rastrigin 1D: ~0 (–∏–¥–µ–∞–ª—å–Ω–æ)

- **Time**: –í—Ä–µ–º—è —Å –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è

### TensorBoard (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω TensorBoard:
```bash
tensorboard --logdir policies/checkpoints/runs
```

–ì—Ä–∞—Ñ–∏–∫–∏:
- Loss vs Steps
- Best Value vs Steps
- Learning Rate schedule

---

## üîß Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞ 1: CUDA Out of Memory

**–°–∏–º–ø—Ç–æ–º—ã:**
```
RuntimeError: CUDA out of memory
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ batch_size –∏–ª–∏ —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
python train.py \
  --config-name train_rastrigin1d_test \
  batch_size=8 \
  model.d_model=32
```

### –ü—Ä–æ–±–ª–µ–º–∞ 2: Loss –Ω–µ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è

**–°–∏–º–ø—Ç–æ–º—ã:**
```
Step 1000 | Loss: 0.6931 (–Ω–µ –º–µ–Ω—è–µ—Ç—Å—è)
```

**–†–µ—à–µ–Ω–∏—è:**
1. –£–º–µ–Ω—å—à–∏—Ç–µ learning rate:
   ```bash
   python train.py --config-name train_rastrigin1d lr=1e-5
   ```

2. –£–≤–µ–ª–∏—á—å—Ç–µ warmup:
   ```bash
   python train.py --config-name train_rastrigin1d training.warmup_steps=500
   ```

3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–∞—è)

### –ü—Ä–æ–±–ª–µ–º–∞ 3: Best value –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è

**–°–∏–º–ø—Ç–æ–º—ã:**
```
Step 1000 | Best: 2.5 (–∑–∞—Å—Ç—Ä—è–ª–æ)
```

**–†–µ—à–µ–Ω–∏—è:**
1. –£–≤–µ–ª–∏—á—å—Ç–µ exploration:
   - –í –∫–æ–¥–µ –º–æ–¥–µ–ª–∏: —É–≤–µ–ª–∏—á—å—Ç–µ temperature sampling

2. –î–æ–ª—å—à–µ –æ–±—É—á–∞–π—Ç–µ:
   ```bash
   python train.py --config-name train_rastrigin1d n_steps=16000
   ```

3. –£–≤–µ–ª–∏—á—å—Ç–µ –µ–º–∫–æ—Å—Ç—å –º–æ–¥–µ–ª–∏:
   ```bash
   python train.py \
     --config-name train_rastrigin1d \
     model.d_model=128 \
     model.n_layers=8
   ```

### –ü—Ä–æ–±–ª–µ–º–∞ 4: –°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

**–°–∏–º–ø—Ç–æ–º—ã:**
- 1 step = 10+ —Å–µ–∫—É–Ω–¥

**–†–µ—à–µ–Ω–∏—è:**
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GPU (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞):
   ```bash
   python train.py --config-name train_rastrigin1d device=cuda
   ```

2. –£–º–µ–Ω—å—à–∏—Ç–µ n_episodes:
   ```bash
   python train.py \
     --config-name train_rastrigin1d \
     training.n_episodes=50
   ```

3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–∞–ª–µ–Ω—å–∫—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞:
   ```bash
   python train.py --config-name train_rastrigin1d_test
   ```

---

## üìà –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

```bash
# –¢–µ—Å—Ç –Ω–∞ —Ç–æ–π –∂–µ —Ñ—É–Ω–∫—Ü–∏–∏
python evaluate_continuous.py \
  --model policies/checkpoints/model_best.pt \
  --function rastrigin \
  --n_trials 100 \
  --budget 50

# –†–µ–∑—É–ª—å—Ç–∞—Ç:
# Mean: 0.45 ¬± 0.18
# Median: 0.38
# Success rate: 92% (< 0.5)
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline

```bash
# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: Random, BO, PABBO
python baseline.py \
  --function rastrigin \
  --methods random bo pabbo \
  --n_trials 100 \
  --budget 50 \
  --pabbo_model policies/checkpoints/model_best.pt

# –†–µ–∑—É–ª—å—Ç–∞—Ç:
# Method          Best Value    Std Dev    Time (s)
# -----------------------------------------------------
# Random          2.34 ¬± 0.89              0.05
# BO (GP)         0.82 ¬± 0.34              1.23
# PABBO           0.45 ¬± 0.18              0.15
```

**–•–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
- PABBO –ª—É—á—à–µ Random (–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ)
- PABBO comparable –∏–ª–∏ –ª—É—á—à–µ BO
- PABBO –±—ã—Å—Ç—Ä–µ–µ BO

---

## üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ production

### 1. –û–±—É—á–∏—Ç–µ —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å

```bash
# –î–ª–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è production
python train.py \
  --config-name train_rastrigin1d \
  n_steps=20000 \
  model.d_model=128 \
  model.n_layers=8

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è –≤: policies/checkpoints/model_best.pt
```

### 2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

```bash
python evaluate_continuous.py \
  --model policies/checkpoints/model_best.pt \
  --function rastrigin \
  --n_trials 500 \
  --budget 100
```

### 3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤ LDA –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

```bash
cd ../lda_hyperopt

python run.py \
  --data your_corpus.npz \
  --algorithms PABBO_Full \
  --pabbo-model ../pabbo_method/policies/checkpoints/model_best.pt \
  --iterations 100 \
  --outdir results
```

---

## üí° Best Practices

1. **–ù–∞—á–Ω–∏—Ç–µ —Å –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞**
   ```bash
   python train.py --config-name train_rastrigin1d_test
   ```

2. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è** (Loss —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è)

3. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ** –µ—Å–ª–∏ —Ç–µ—Å—Ç —É—Å–ø–µ—à–µ–Ω

4. **–¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏** –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º

5. **–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ checkpoint'—ã —Ä–µ–≥—É–ª—è—Ä–Ω–æ**

6. **–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ hyperparameters** –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–±–æ—Ç–∞—é—Ç

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

### –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

–ò–∑ `data/function.py`:
- `forrester1D` - 1D —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è
- `sinexp1D` - sin(x) + exp(x)
- `rastrigin1D` - –º–Ω–æ–≥–æ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤
- `branin2D` - 2D –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è
- `beale2D` - 2D —Å –∫—Ä—É—Ç—ã–º –ª–∞–Ω–¥—à–∞—Ñ—Ç–æ–º
- `hartmann6D` - 6D —Å–ª–æ–∂–Ω–∞—è
- `ackley6D` - 6D –º–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è
- `rastrigin6D` - 6D Rastrigin
- `levy6D` - 6D Levy
- `rosenbrock6D` - 6D Rosenbrock

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

**–î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞:**
```yaml
n_steps: 2000
model: {d_model: 32, n_layers: 3, n_heads: 4}
batch_size: 16
```

**–î–ª—è production:**
```yaml
n_steps: 20000
model: {d_model: 128, n_layers: 8, n_heads: 8}
batch_size: 32
```

**–î–ª—è LDA:**
```yaml
n_steps: 10000
discrete: true
bounds: {T_min: 2, T_max: 1000}
model: {d_model: 64, n_layers: 6, n_heads: 8}
```

---

## ‚úÖ Checklist –¥–ª—è —É—Å–ø–µ—à–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

- [ ] –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã (torch, botorch, etc.)
- [ ] –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç (`train_rastrigin1d_test`)
- [ ] Loss —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
- [ ] Best value —É–ª—É—á—à–∞–µ—Ç—Å—è
- [ ] –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ `policies/checkpoints/model_best.pt`
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
- [ ] –†–∞–±–æ—Ç–∞–µ—Ç –≤ `lda_hyperopt/run.py` —Å `--pabbo-model`

---

## üéâ –ì–æ—Ç–æ–≤–æ!

–¢–µ–ø–µ—Ä—å –≤—ã –∑–Ω–∞–µ—Ç–µ –∫–∞–∫:
1. ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
2. ‚úÖ –ë—ã—Å—Ç—Ä–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ (10 –º–∏–Ω)
3. ‚úÖ –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (30-60 –º–∏–Ω)
4. ‚úÖ –ö–∞—Å—Ç–æ–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ LDA
5. ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:**
```bash
cd pabbo_method
python train.py --config-name train_rastrigin1d_test
# –ü–æ–¥–æ–∂–¥–∞—Ç—å 10 –º–∏–Ω—É—Ç
cd ../lda_hyperopt
python run.py --algorithms PABBO_Full --pabbo-model ../pabbo_method/policies/checkpoints/model_best.pt
```

–£–¥–∞—á–∏! üöÄ
