# Гиперпараметры оптимизаторов LDA

Этот документ описывает все гиперпараметры для каждого алгоритма оптимизации.

## Общие параметры

**Для всех алгоритмов:**
- `T_bounds`: (2, 1000) - границы для параметра T (число топиков)
- `seed`: 42 - случайный seed для воспроизводимости
- `early_stop_eps_pct`: 0.01 (1%) - порог относительного улучшения для ранней остановки
- `max_no_improvement`: 5 - количество итераций без улучшения для ранней остановки
- `initial_population`: Фиксированная начальная популяция из 20 значений T

**Параметры LDA:**
- `max_iter`: 60 - максимальное количество итераций LDA
- `batch_size`: 2048 - размер батча для online learning
- `learning_method`: "online" - метод обучения LDA
- `alpha`: 1/T - параметр Дирихле для распределения документ-топик
- `eta`: 1/T - параметр Дирихле для распределения топик-слово

---

## 1. Genetic Algorithm (GA)

### Гиперпараметры

```python
cxpb = 0.9          # Вероятность кроссовера
mutpb = 0.2         # Вероятность мутации
tournsize = 3       # Размер турнира для селекции
elite = 5           # Количество элитных особей (лучшие всегда выживают)
dT = 5              # Максимальный шаг мутации для T
pop_size = 20       # Размер популяции (из initial_population)
```

### Как работает

**Инициализация:**
1. Загружается фиксированная начальная популяция из 20 значений T
2. Для каждого T вычисляется fitness = perplexity(T, alpha=1/T, eta=1/T)
3. Лучшие особи сохраняются

**Основной цикл (каждая итерация):**
1. **Селекция**: Турнирная селекция с размером турнира=3
   - Выбирается tournsize случайных особей
   - Из них выбирается лучшая (с минимальным perplexity)
   - Повторяется pop_size раз для создания родительского пула

2. **Кроссовер**: С вероятностью cxpb=0.9 применяется binary crossover
   - Два родителя обмениваются битами своих значений T
   - Создается 2 потомка
   - Потомки clamp'ятся в границы [2, 1000]

3. **Мутация**: С вероятностью mutpb=0.2 применяется integer mutation
   - Случайное изменение T на ±dT с равномерным распределением
   - T = T + random.randint(-dT, dT)
   - Результат clamp'ится в границы [2, 1000]

4. **Оценка**: Все новые особи оцениваются через LDA

5. **Элитизм**: Лучшие elite=5 особей из старой популяции всегда переходят в новую

6. **Замена**: Новая популяция = elite + лучшие (pop_size - elite) из потомков

**Остановка:**
- Когда относительное улучшение < 1% в течение 5 итераций подряд
- ИЛИ достигнуто максимальное количество итераций

**Преимущества GA:**
- Хороший баланс exploration/exploitation через кроссовер и мутацию
- Элитизм гарантирует что лучшие решения не теряются
- Эффективен для дискретных пространств

---

## 2. Evolution Strategy (ES)

### Гиперпараметры

```python
mu = 5              # Количество родителей (μ)
lmbda = 10          # Количество потомков (λ)
dT = 5              # Максимальный шаг мутации для T
pop_size = 20       # Начальная популяция (из initial_population)
```

### Как работает

**Инициализация:**
1. Загружается фиксированная начальная популяция из 20 значений T
2. Для каждого T вычисляется fitness = perplexity(T, alpha=1/T, eta=1/T)
3. Выбираются лучшие mu=5 особей как родители

**Основной цикл (каждая итерация):**
1. **Генерация потомков**:
   - Для каждого из lmbda=10 потомков:
   - Выбирается случайный родитель из mu=5
   - Применяется мутация: T_child = T_parent + N(0, dT)
   - N(0, dT) - нормальное распределение со средним 0 и стандартным отклонением dT
   - Результат округляется до целого и clamp'ится в [2, 1000]

2. **Оценка**: Все lmbda=10 потомков оцениваются через LDA

3. **Селекция (μ + λ)**:
   - Объединяются mu родителей + lmbda потомков = mu+lmbda=15 особей
   - Выбираются лучшие mu=5 как новые родители для следующей итерации

**Остановка:**
- Когда относительное улучшение < 1% в течение 5 итераций подряд
- ИЛИ достигнуто максимальное количество итераций

**Преимущества ES:**
- Простота: нет кроссовера, только мутация
- (μ + λ) стратегия обеспечивает элитизм
- Хорошо работает для непрерывных и дискретных пространств
- Самоадаптация через нормальное распределение

---

## 3. PABBO Simple

### Гиперпараметры

```python
exploration_rate = 0.3      # Вероятность exploration vs exploitation
temperature_decay = 0.95    # Коэффициент уменьшения температуры
min_temperature = 0.1       # Минимальная температура
n_initial = 20              # Количество начальных точек (из initial_population)
```

### Как работает

**Инициализация:**
1. Загружается фиксированная начальная популяция из 20 значений T
2. Все 20 точек оцениваются через LDA
3. Запоминается лучшая точка
4. Начальная температура = 1.0

**Основной цикл (каждая итерация):**

1. **Выбор стратегии**: С вероятностью exploration_rate=0.3:
   - **Exploration (30% случаев)**:
     - T_new = random.randint(2, 1000)
     - Случайная точка из всего пространства

   - **Exploitation (70% случаев)**:
     - Берутся top-5 лучших точек из всех оцененных
     - Выбирается случайная из них как центр
     - Вычисляется search_radius = (1000-2) * temperature
     - T_new = N(T_center, search_radius) - нормальное распределение вокруг центра
     - Результат clamp'ится в [2, 1000]

2. **Оценка**: T_new оценивается через LDA

3. **Обновление**:
   - Если T_new лучше текущего лучшего → обновляется best
   - Точка (T_new, fitness) добавляется в список оцененных точек

4. **Decay температуры**:
   - temperature = max(min_temperature, temperature * temperature_decay)
   - temperature = max(0.1, temperature * 0.95)
   - Со временем поиск становится более локальным

**Остановка:**
- Когда относительное улучшение < 1% в течение 5 итераций подряд
- ИЛИ достигнуто максимальное количество итераций

**Преимущества PABBO Simple:**
- Адаптивный баланс exploration/exploitation
- Температура автоматически уменьшается (от глобального к локальному поиску)
- Простая реализация, не требует внешних моделей
- Запоминает все оцененные точки и использует их для exploitation

---

## 4. PABBO Full (с Transformer)

### Гиперпараметры

```python
model_path = None               # Путь к обученной Transformer модели
exploration_rate = 0.3          # Вероятность exploration vs exploitation
temperature_decay = 0.95        # Коэффициент уменьшения температуры
min_temperature = 0.1           # Минимальная температура
n_initial = 20                  # Количество начальных точек (из initial_population)

# Параметры Transformer модели (если доступна):
d_model = 256                   # Размерность модели
n_heads = 8                     # Количество attention heads
n_layers = 6                    # Количество transformer layers
```

### Как работает

**Если модель НЕ доступна:**
- Fallback на PABBO Simple (см. выше)
- Выводится warning о недоступности PyTorch/модели

**Если модель доступна:**

**Инициализация:**
1. Загружается обученная Transformer модель из checkpoint
2. Загружается фиксированная начальная популяция из 20 значений T
3. Все 20 точек оцениваются через LDA
4. История оценок подается в Transformer для инициализации

**Основной цикл (каждая итерация):**

1. **Выбор стратегии**: С вероятностью exploration_rate=0.3:
   - **Exploration (30% случаев)**:
     - T_new = random.randint(2, 1000)
     - Случайная точка

   - **Exploitation с Transformer (70% случаев)**:
     - Подготовка входа: история (T, fitness) пар преобразуется в sequence
     - Transformer forward pass: encoder анализирует историю
     - Decoder генерирует distribution над пространством T
     - Сэмплируется T_new из этого distribution
     - Применяется temperature для control exploration/exploitation

2. **Оценка**: T_new оценивается через LDA

3. **Обновление**:
   - Результат добавляется в историю
   - Transformer обновляет свое понимание функции
   - Если T_new лучше → обновляется best

4. **Decay температуры**:
   - temperature = max(min_temperature, temperature * temperature_decay)

**Остановка:**
- Когда относительное улучшение < 1% в течение 5 итераций подряд
- ИЛИ достигнуто максимальное количество итераций

**Преимущества PABBO Full:**
- Transformer учится на паттернах из множества задач оптимизации
- Meta-learning: переносит знания между разными функциями
- Более интеллектуальный exploitation через learned policy
- Может быстрее находить хорошие решения за счет prior knowledge

**Требования:**
- Обученная модель (train в pabbo_method/)
- PyTorch, botorch, gpytorch
- Checkpoint с весами Transformer

---

## Сравнение алгоритмов

| Характеристика | GA | ES | PABBO Simple | PABBO Full |
|----------------|----|----|--------------|------------|
| **Exploration** | Кроссовер + мутация | Мутация с N(0, σ) | Random sampling (30%) | Random + Transformer (30%) |
| **Exploitation** | Селекция + элитизм | (μ+λ) селекция | Gaussian вокруг top-5 | Transformer policy |
| **Популяция** | 20 особей | 5 родителей + 10 потомков | Все оцененные точки | Все оцененные точки |
| **Адаптация** | Статичные параметры | Статичные параметры | Temperature decay | Temperature + learned policy |
| **Сложность** | Средняя | Низкая | Низкая | Высокая (требует модель) |
| **Meta-learning** | Нет | Нет | Нет | Да (через Transformer) |
| **Память** | Только текущая популяция | Только μ+λ | Все точки | Все точки + model weights |

---

## Как выбрать алгоритм

**GA** - хороший выбор если:
- Нужен проверенный, надежный алгоритм
- Важен баланс exploration/exploitation
- Дискретное пространство параметров

**ES** - хороший выбор если:
- Нужна простота и скорость
- Непрерывное или дискретное пространство
- Ограниченные вычислительные ресурсы

**PABBO Simple** - хороший выбор если:
- Нужна адаптивность (temperature decay)
- Важна память всех оцененных точек
- Нет возможности обучить Transformer

**PABBO Full** - хороший выбор если:
- Есть обученная модель
- Нужен transfer learning между задачами
- Много похожих задач оптимизации
- Вычислительные ресурсы для inference модели

---

## Общие рекомендации

1. **Начните с GA или PABBO Simple** - они показывают хорошие результаты без дополнительных требований

2. **Запустите все алгоритмы** для сравнения на вашей задаче

3. **Настройка гиперпараметров**:
   - Увеличьте iterations если алгоритм улучшается к концу
   - Увеличьте max_no_improvement если много шума в оценках
   - Для GA: увеличьте elite для более агрессивного exploitation
   - Для ES: увеличьте λ для большего exploration
   - Для PABBO: уменьшите exploration_rate для быстрой сходимости

4. **Early stopping** работает автоматически и экономит время на сходящихся задачах

5. **Начальная популяция** одинакова для всех → честное сравнение
