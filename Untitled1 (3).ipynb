{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### MAIN_CODE"
   ],
   "metadata": {
    "id": "Cg21VFN0JynV"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tiVGOw-T9pEy",
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:40.500305Z",
     "start_time": "2025-10-26T15:50:40.494038Z"
    }
   },
   "source": "import math\nimport time\nimport copy\nimport numpy as np\nimport scipy.sparse as sp\nfrom gensim.models import LdaModel\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom typing import Callable, Tuple, Dict, List\nfrom sklearn.decomposition import LatentDirichletAllocation\nimport random\nfrom deap import base, creator, tools\nimport os\nimport csv\nimport json\nfrom tensorboardX import SummaryWriter\nfrom functools import wraps\n\n# Decorators for clean code\ndef timing_decorator(func):\n    \"\"\"Decorator to measure execution time\"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        start = time.perf_counter()\n        result = func(*args, **kwargs)\n        end = time.perf_counter()\n        print(f\"[TIMING] {func.__name__} completed in {end - start:.2f}s\")\n        return result\n    return wrapper\n\ndef log_decorator(prefix=\"\"):\n    \"\"\"Decorator for pretty logging\"\"\"\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            print(f\"[{prefix}] Starting {func.__name__}...\")\n            result = func(*args, **kwargs)\n            print(f\"[{prefix}] {func.__name__} completed!\")\n            return result\n        return wrapper\n    return decorator",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def load_bow_pair(train_path: str, val_path: str):\n",
    "    Xtr = sp.load_npz(train_path).tocsr(copy=False)\n",
    "    Xva = sp.load_npz(val_path).tocsr(copy=False)\n",
    "    return Xtr, Xva"
   ],
   "metadata": {
    "id": "VYDIrQLj-enq",
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:43.187811Z",
     "start_time": "2025-10-26T15:50:43.185088Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "Xtr, Xva = load_bow_pair(\"data/X_agnews_train_bow.npz\", \"data/X_agnews_val_bow.npz\")",
   "metadata": {
    "id": "grnTmfsTBDFL",
    "ExecuteTime": {
     "end_time": "2025-10-26T15:50:56.102584Z",
     "start_time": "2025-10-26T15:50:56.088401Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "def lda_blackbox(\n",
    "    T: int,\n",
    "    alpha: float,\n",
    "    eta: float,\n",
    "    *,\n",
    "    seed: int = 42,\n",
    "    max_iter: int = 400,\n",
    "    batch_size: int = 2048,\n",
    "    learning_method: str = \"online\"\n",
    "):\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=int(T),\n",
    "        doc_topic_prior=float(alpha),\n",
    "        topic_word_prior=float(eta),\n",
    "        learning_method=learning_method,\n",
    "        max_iter=int(max_iter),\n",
    "        batch_size=int(batch_size),\n",
    "        random_state=int(seed),\n",
    "        evaluate_every=-1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    t0 = time.perf_counter()\n",
    "    lda.fit(Xtr)\n",
    "    fit_time = time.perf_counter() - t0\n",
    "    ppl = float(lda.perplexity(Xva))\n",
    "    return ppl"
   ],
   "metadata": {
    "id": "CKTS0AMIpP8O",
    "ExecuteTime": {
     "end_time": "2025-10-26T15:51:35.785724Z",
     "start_time": "2025-10-26T15:51:35.780366Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "try:\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "except Exception:\n",
    "    pass\n"
   ],
   "metadata": {
    "id": "KoQZPMccqB4V",
    "ExecuteTime": {
     "end_time": "2025-10-26T15:51:39.259469Z",
     "start_time": "2025-10-26T15:51:39.256744Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "def _clamp(x, lo, hi):\n",
    "    return lo if x < lo else hi if x > hi else x"
   ],
   "metadata": {
    "id": "s7y7cFkCqFhZ",
    "ExecuteTime": {
     "end_time": "2025-10-26T15:51:41.753507Z",
     "start_time": "2025-10-26T15:51:41.750388Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "class GAOptimizer:\n    \"\"\"\n    Genetic Algorithm optimizer that searches only for T parameter.\n    Alpha and eta are automatically set to 1/T.\n    \"\"\"\n    def __init__(\n        self,\n        obj,\n        eval_func,\n        T_bounds=(2, 1000),\n        *,\n        seed=42,\n        cxpb=0.9,\n        mutpb=0.2,\n        tournsize=3,\n        elite=5,\n        dT=5,\n        early_stop_eps_pct=0.01,\n        max_no_improvement=5\n    ):\n        self.obj = obj\n        self.eval_func = eval_func\n        self.Tb = T_bounds\n        self.seed = int(seed)\n        self.cxpb = cxpb\n        self.mutpb = mutpb\n        self.tournsize = tournsize\n        self.elite = elite\n        self.dT = int(dT)\n        self.early_stop_eps_pct = float(early_stop_eps_pct)\n        self.max_no_improvement = int(max_no_improvement)\n        self.toolbox = base.Toolbox()\n        \n        random.seed(self.seed)\n        np.random.seed(self.seed)\n\n        def create_individual():\n            T = random.randint(self.Tb[0], self.Tb[1])\n            return creator.Individual([T])\n\n        self.toolbox.register(\"individual\", create_individual)\n        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n        self.toolbox.register(\"evaluate\", self._evaluate)\n        self.toolbox.register(\"select\", tools.selTournament, tournsize=self.tournsize)\n        self.toolbox.register(\"clone\", copy.deepcopy)\n\n    def _decode(self, ind):\n        \"\"\"Decode individual: T -> (T, alpha=1/T, eta=1/T)\"\"\"\n        T = int(round(ind[0]))\n        T = _clamp(T, self.Tb[0], self.Tb[1])\n        alpha = 1.0 / T\n        eta = 1.0 / T\n        return T, float(alpha), float(eta)\n\n    def _evaluate(self, ind):\n        T, a, e = self._decode(ind)\n        try:\n            v = float(self.obj(T, a, e))\n        except Exception:\n            v = float(\"inf\")\n        return (v,)\n\n    def _cx(self, ind1, ind2):\n        \"\"\"Crossover for T only\"\"\"\n        if random.random() < 0.5:\n            ind1[0], ind2[0] = ind2[0], ind1[0]\n        return ind1, ind2\n\n    def _mut(self, ind):\n        \"\"\"Mutation for T only\"\"\"\n        ind[0] = _clamp(\n            int(round(ind[0] + random.randint(-self.dT, self.dT))), \n            self.Tb[0], \n            self.Tb[1]\n        )\n        return (ind,)\n\n    def _save_population(self, pop, gen, outdir):\n        pop_file = os.path.join(outdir, f\"population_gen_{gen}.csv\")\n        with open(pop_file, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(['individual_id', 'T', 'alpha', 'eta', 'fitness'])\n            for i, ind in enumerate(pop):\n                T, a, e = self._decode(ind)\n                writer.writerow([i, T, a, e, ind.fitness.values[0]])\n\n    def run(self, gens=200, pop_size=10, writer=None, outdir=None):\n        print(f\"[GA] Starting optimization: {gens} generations, population size {pop_size}\")\n        print(f\"[GA] T bounds: {self.Tb}, alpha=1/T, eta=1/T\")\n        pop = self.toolbox.population(n=pop_size)\n        hall = tools.HallOfFame(maxsize=self.elite)\n        history = []\n        t0 = time.perf_counter()\n        no_improvement_count = 0\n        prev_max_ppl = float('inf')\n\n        print(f\"[GA] Evaluating initial population...\")\n        for ind in pop:\n            ind.fitness.values = self.toolbox.evaluate(ind)\n        hall.update(pop)\n        best_sofar = min(pop, key=lambda x: x.fitness.values[0])\n\n        Tb, ab, eb = self._decode(best_sofar)\n        best_metrics = self.eval_func(Tb, ab, eb)\n        prev_max_ppl = best_metrics['doc_ppl_val_max']\n\n        print(f\"[GA] Initial best: T={Tb}, alpha={ab:.6f}, eta={eb:.6f}\")\n        print(f\"[GA]   corpus_ppl_val={best_metrics['corpus_ppl_val']:.4f}\")\n        print(f\"[GA]   doc_ppl_val_mean={best_metrics['doc_ppl_val_mean']:.4f}\")\n        if 'doc_ppl_val_var' in best_metrics:\n            print(f\"[GA]   doc_ppl_val_var={best_metrics['doc_ppl_val_var']:.4f}\")\n        print(f\"[GA]   doc_ppl_val_max={best_metrics['doc_ppl_val_max']:.4f}\")\n\n        if outdir:\n            self._save_population(pop, 0, outdir)\n\n        for g in range(gens):\n            gs = time.perf_counter()\n            elites = tools.selBest(pop, self.elite)\n            offspring = self.toolbox.select(pop, len(pop) - self.elite)\n            offspring = list(map(self.toolbox.clone, offspring))\n            for i in range(0, len(offspring) - 1, 2):\n                if random.random() < self.cxpb:\n                    self._cx(offspring[i], offspring[i + 1])\n            for i in range(len(offspring)):\n                if random.random() < self.mutpb:\n                    self._mut(offspring[i])\n                del offspring[i].fitness.values\n            invalid = [ind for ind in offspring if not ind.fitness.valid]\n            for ind in invalid:\n                ind.fitness.values = self.toolbox.evaluate(ind)\n            pop = elites + offspring\n            hall.update(pop)\n\n            cur_best = min(pop, key=lambda x: x.fitness.values[0])\n            if cur_best.fitness.values[0] < best_sofar.fitness.values[0]:\n                best_sofar = cur_best\n\n            Tb, ab, eb = self._decode(best_sofar)\n            best_metrics = self.eval_func(Tb, ab, eb)\n\n            gen_time = time.perf_counter() - gs\n            cum_time = time.perf_counter() - t0\n\n            vals = [ind.fitness.values[0] for ind in pop]\n            pop_mean = float(np.mean(vals))\n            pop_std = float(np.std(vals))\n            pop_min = float(np.min(vals))\n            pop_max = float(np.max(vals))\n\n            current_max_ppl = best_metrics['doc_ppl_val_max']\n            relative_change = abs(current_max_ppl - prev_max_ppl) / prev_max_ppl if prev_max_ppl > 0 else float('inf')\n            if relative_change <= self.early_stop_eps_pct:\n                no_improvement_count += 1\n            else:\n                no_improvement_count = 0\n            prev_max_ppl = current_max_ppl\n\n            print(f\"[GA] Gen {g+1}/{gens} | Best: T={Tb}, alpha={ab:.6f}, eta={eb:.6f}\")\n            line = f\"     corpus_ppl_val={best_metrics['corpus_ppl_val']:.4f}, doc_ppl_val_mean={best_metrics['doc_ppl_val_mean']:.4f}\"\n            if 'doc_ppl_val_var' in best_metrics:\n                line += f\", doc_ppl_val_var={best_metrics['doc_ppl_val_var']:.4f}\"\n            line += f\", doc_ppl_val_max={best_metrics['doc_ppl_val_max']:.4f}\"\n            print(line)\n            print(f\"     Pop: mean={pop_mean:.4f}, std={pop_std:.4f}, min={pop_min:.4f}, max={pop_max:.4f}\")\n            print(f\"     Time: {gen_time:.2f}s (total: {cum_time:.2f}s) | No improvement: {no_improvement_count}/{self.max_no_improvement} (≤ {self.early_stop_eps_pct*100:.2f}% change)\")\n\n            if writer:\n                iter_num = g + 1\n                writer.add_scalar(\"Best/corpus_ppl_val\", best_metrics['corpus_ppl_val'], iter_num)\n                writer.add_scalar(\"Best/corpus_ppl_train\", best_metrics.get('corpus_ppl_train', float('nan')), iter_num)\n                writer.add_scalar(\"Best/doc_ppl_val_mean\", best_metrics['doc_ppl_val_mean'], iter_num)\n                writer.add_scalar(\"Best/doc_ppl_val_max\", best_metrics['doc_ppl_val_max'], iter_num)\n                writer.add_scalar(\"Best/doc_ppl_train_mean\", best_metrics.get('doc_ppl_train_mean', float('nan')), iter_num)\n                if 'doc_ppl_val_var' in best_metrics:\n                    writer.add_scalar(\"Best/doc_ppl_val_var\", best_metrics['doc_ppl_val_var'], iter_num)\n                    writer.add_scalar(\"Best/doc_ppl_train_var\", best_metrics.get('doc_ppl_train_var', float('nan')), iter_num)\n                writer.add_scalar(\"Best/T\", Tb, iter_num)\n                writer.add_scalar(\"Best/alpha\", ab, iter_num)\n                writer.add_scalar(\"Best/eta\", eb, iter_num)\n                writer.add_scalar(\"Population/mean_fitness\", pop_mean, iter_num)\n                writer.add_scalar(\"Population/std_fitness\", pop_std, iter_num)\n                writer.add_scalar(\"Population/min_fitness\", pop_min, iter_num)\n                writer.add_scalar(\"Population/max_fitness\", pop_max, iter_num)\n                writer.add_scalar(\"Time/step_time\", gen_time, iter_num)\n                writer.add_scalar(\"Time/cumulative\", cum_time, iter_num)\n                writer.add_scalar(\"EarlyStopping/no_improvement_count\", no_improvement_count, iter_num)\n                writer.add_scalar(\"EarlyStopping/relative_change_pct\", relative_change * 100, iter_num)\n                T_vals = [self._decode(ind)[0] for ind in pop]\n                alpha_vals = [self._decode(ind)[1] for ind in pop]\n                eta_vals = [self._decode(ind)[2] for ind in pop]\n                writer.add_histogram(\"Population/T_distribution\", np.array(T_vals), iter_num)\n                writer.add_histogram(\"Population/alpha_distribution\", np.array(alpha_vals), iter_num)\n                writer.add_histogram(\"Population/eta_distribution\", np.array(eta_vals), iter_num)\n                writer.add_histogram(\"Population/fitness_distribution\", np.array(vals), iter_num)\n                writer.add_scalar(\"Time/avg_step_time_running\", cum_time / iter_num, iter_num)\n            history.append({\n                \"iter\": g,\n                \"best_corpus_ppl_val\": best_metrics['corpus_ppl_val'],\n                \"best_corpus_ppl_train\": best_metrics.get('corpus_ppl_train', float('nan')),\n                \"best_doc_ppl_val_mean\": best_metrics['doc_ppl_val_mean'],\n                \"best_doc_ppl_val_var\": best_metrics.get('doc_ppl_val_var', float('nan')),\n                \"best_doc_ppl_val_max\": best_metrics['doc_ppl_val_max'],\n                \"best_doc_ppl_train_mean\": best_metrics.get('doc_ppl_train_mean', float('nan')),\n                \"best_doc_ppl_train_var\": best_metrics.get('doc_ppl_train_var', float('nan')),\n                \"pop_mean\": pop_mean,\n                \"pop_std\": pop_std,\n                \"pop_min\": pop_min,\n                \"pop_max\": pop_max,\n                \"T_best\": Tb,\n                \"alpha_best\": ab,\n                \"eta_best\": eb,\n                \"step_time\": gen_time,\n                \"cum_time\": cum_time,\n                \"no_improvement_count\": no_improvement_count,\n                \"relative_change_pct\": relative_change * 100\n            })\n\n            if outdir:\n                self._save_population(pop, g + 1, outdir)\n\n            if no_improvement_count >= self.max_no_improvement:\n                print(f\"[GA] Early stopping: |Δ max(doc_ppl_val)|/prev ≤ {self.early_stop_eps_pct*100:.2f}% for {self.max_no_improvement} iterations\")\n                break\n\n        final_cum_time = time.perf_counter() - t0\n        print(f\"[GA] Optimization complete! Total time: {final_cum_time:.2f}s\")\n        print(f\"[GA] Final best: T={Tb}, alpha={ab:.6f}, eta={eb:.6f}\")\n        print(f\"[GA]   corpus_ppl_val={best_metrics['corpus_ppl_val']:.4f}\")\n        print(f\"[GA]   doc_ppl_val_mean={best_metrics['doc_ppl_val_mean']:.4f}\")\n        if 'doc_ppl_val_var' in best_metrics:\n            print(f\"[GA]   doc_ppl_val_var={best_metrics['doc_ppl_val_var']:.4f}\")\n        print(f\"[GA]   doc_ppl_val_max={best_metrics['doc_ppl_val_max']:.4f}\")\n\n        best = self._decode(best_sofar)\n        return {\n            \"best\": {\n                \"T\": best[0],\n                \"alpha\": best[1],\n                \"eta\": best[2],\n                **best_metrics\n            },\n            \"history\": history,\n            \"total_time\": final_cum_time,\n            \"avg_step_time\": float(np.mean([h[\"step_time\"] for h in history])) if history else 0.0,\n            \"stopped_early\": no_improvement_count >= self.max_no_improvement\n        }\n",
   "metadata": {
    "id": "4Kdm9lmmqJf1",
    "ExecuteTime": {
     "end_time": "2025-10-26T15:51:43.583373Z",
     "start_time": "2025-10-26T15:51:43.571427Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "class ESOptimizer:\n    \"\"\"\n    Evolution Strategy optimizer that searches only for T parameter.\n    Alpha and eta are automatically set to 1/T.\n    \"\"\"\n    def __init__(\n        self,\n        obj,\n        eval_func,\n        T_bounds=(2, 1000),\n        *,\n        seed=42,\n        mu=12,\n        lmbda=48,\n        dT=5,\n        early_stop_eps_pct=0.01,\n        max_no_improvement=5\n    ):\n        self.obj = obj\n        self.eval_func = eval_func\n        self.Tb = T_bounds\n        self.seed = int(seed)\n        self.mu = int(mu)\n        self.lmbda = int(lmbda)\n        self.dT = int(dT)\n        self.early_stop_eps_pct = float(early_stop_eps_pct)\n        self.max_no_improvement = int(max_no_improvement)\n        self.toolbox = base.Toolbox()\n        \n        random.seed(self.seed)\n        np.random.seed(self.seed)\n\n        def create_individual():\n            T = random.randint(self.Tb[0], self.Tb[1])\n            return creator.Individual([T])\n\n        self.toolbox.register(\"individual\", create_individual)\n        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n        self.toolbox.register(\"evaluate\", self._evaluate)\n\n    def _clamp(self, ind):\n        \"\"\"Clamp T to bounds\"\"\"\n        ind[0] = _clamp(int(round(ind[0])), self.Tb[0], self.Tb[1])\n\n    def _decode(self, ind):\n        \"\"\"Decode individual: T -> (T, alpha=1/T, eta=1/T)\"\"\"\n        T = int(round(ind[0]))\n        T = _clamp(T, self.Tb[0], self.Tb[1])\n        alpha = 1.0 / T\n        eta = 1.0 / T\n        return T, float(alpha), float(eta)\n\n    def _evaluate(self, ind):\n        T, a, e = self._decode(ind)\n        try:\n            v = float(self.obj(T, a, e))\n        except Exception:\n            v = float(\"inf\")\n        return (v,)\n\n    def _mut(self, parent):\n        \"\"\"Mutation for T only\"\"\"\n        child = creator.Individual(parent[:])\n        child[0] = int(round(child[0] + random.randint(-self.dT, self.dT)))\n        self._clamp(child)\n        return child\n\n    def _save_population(self, pop, step, outdir):\n        pop_file = os.path.join(outdir, f\"population_step_{step}.csv\")\n        with open(pop_file, 'w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(['individual_id', 'T', 'alpha', 'eta', 'fitness'])\n            for i, ind in enumerate(pop):\n                T, a, e = self._decode(ind)\n                writer.writerow([i, T, a, e, ind.fitness.values[0]])\n\n    def run(self, steps=24, writer=None, outdir=None):\n        print(f\"[ES] Starting optimization: {steps} steps, mu={self.mu}, lambda={self.lmbda}\")\n        print(f\"[ES] T bounds: {self.Tb}, alpha=1/T, eta=1/T\")\n        parents = self.toolbox.population(n=self.mu)\n        history = []\n        t0 = time.perf_counter()\n        no_improvement_count = 0\n        prev_max_ppl = float('inf')\n\n        print(f\"[ES] Evaluating initial population...\")\n        for ind in parents:\n            ind.fitness.values = self.toolbox.evaluate(ind)\n        best_sofar = min(parents, key=lambda x: x.fitness.values[0])\n\n        Tb, ab, eb = self._decode(best_sofar)\n        best_metrics = self.eval_func(Tb, ab, eb)\n        prev_max_ppl = best_metrics['doc_ppl_val_max']\n\n        print(f\"[ES] Initial best: T={Tb}, alpha={ab:.6f}, eta={eb:.6f}\")\n        print(f\"[ES]   corpus_ppl_val={best_metrics['corpus_ppl_val']:.4f}\")\n        print(f\"[ES]   doc_ppl_val_mean={best_metrics['doc_ppl_val_mean']:.4f}\")\n        if 'doc_ppl_val_var' in best_metrics:\n            print(f\"[ES]   doc_ppl_val_var={best_metrics['doc_ppl_val_var']:.4f}\")\n        print(f\"[ES]   doc_ppl_val_max={best_metrics['doc_ppl_val_max']:.4f}\")\n\n        if outdir:\n            self._save_population(parents, 0, outdir)\n\n        for s in range(steps):\n            step_start = time.perf_counter()\n            off = []\n            for _ in range(self.lmbda):\n                p = random.choice(parents)\n                c = self._mut(p)\n                c.fitness.values = self.toolbox.evaluate(c)\n                off.append(c)\n\n            pool = parents + off\n            pool.sort(key=lambda x: x.fitness.values[0])\n            parents = [creator.Individual(ind[:]) for ind in pool[:self.mu]]\n            for i in range(self.mu):\n                parents[i].fitness.values = pool[i].fitness.values\n\n            cur_best = parents[0]\n            if cur_best.fitness.values[0] < best_sofar.fitness.values[0]:\n                best_sofar = cur_best\n\n            Tb, ab, eb = self._decode(best_sofar)\n            best_metrics = self.eval_func(Tb, ab, eb)\n\n            step_time = time.perf_counter() - step_start\n            cum_time = time.perf_counter() - t0\n\n            vals = [ind.fitness.values[0] for ind in parents]\n            pop_mean = float(np.mean(vals))\n            pop_std = float(np.std(vals))\n            pop_min = float(np.min(vals))\n            pop_max = float(np.max(vals))\n\n            current_max_ppl = best_metrics['doc_ppl_val_max']\n            relative_change = abs(current_max_ppl - prev_max_ppl) / prev_max_ppl if prev_max_ppl > 0 else float('inf')\n            if relative_change <= self.early_stop_eps_pct:\n                no_improvement_count += 1\n            else:\n                no_improvement_count = 0\n            prev_max_ppl = current_max_ppl\n\n            print(f\"[ES] Step {s+1}/{steps} | Best: T={Tb}, alpha={ab:.6f}, eta={eb:.6f}\")\n            line = f\"     corpus_ppl_val={best_metrics['corpus_ppl_val']:.4f}, doc_ppl_val_mean={best_metrics['doc_ppl_val_mean']:.4f}\"\n            if 'doc_ppl_val_var' in best_metrics:\n                line += f\", doc_ppl_val_var={best_metrics['doc_ppl_val_var']:.4f}\"\n            line += f\", doc_ppl_val_max={best_metrics['doc_ppl_val_max']:.4f}\"\n            print(line)\n            print(f\"     Parents: mean={pop_mean:.4f}, std={pop_std:.4f}, min={pop_min:.4f}, max={pop_max:.4f}\")\n            print(f\"     Time: {step_time:.2f}s (total: {cum_time:.2f}s) | No improvement: {no_improvement_count}/{self.max_no_improvement} (≤ {self.early_stop_eps_pct*100:.2f}% change)\")\n\n            if writer:\n                iter_num = s + 1\n                writer.add_scalar(\"Best/corpus_ppl_val\", best_metrics['corpus_ppl_val'], iter_num)\n                writer.add_scalar(\"Best/corpus_ppl_train\", best_metrics.get('corpus_ppl_train', float('nan')), iter_num)\n                writer.add_scalar(\"Best/doc_ppl_val_mean\", best_metrics['doc_ppl_val_mean'], iter_num)\n                writer.add_scalar(\"Best/doc_ppl_val_max\", best_metrics['doc_ppl_val_max'], iter_num)\n                writer.add_scalar(\"Best/doc_ppl_train_mean\", best_metrics.get('doc_ppl_train_mean', float('nan')), iter_num)\n                if 'doc_ppl_val_var' in best_metrics:\n                    writer.add_scalar(\"Best/doc_ppl_val_var\", best_metrics['doc_ppl_val_var'], iter_num)\n                    writer.add_scalar(\"Best/doc_ppl_train_var\", best_metrics.get('doc_ppl_train_var', float('nan')), iter_num)\n                writer.add_scalar(\"Best/T\", Tb, iter_num)\n                writer.add_scalar(\"Best/alpha\", ab, iter_num)\n                writer.add_scalar(\"Best/eta\", eb, iter_num)\n                writer.add_scalar(\"Population/mean_fitness\", pop_mean, iter_num)\n                writer.add_scalar(\"Population/std_fitness\", pop_std, iter_num)\n                writer.add_scalar(\"Population/min_fitness\", pop_min, iter_num)\n                writer.add_scalar(\"Population/max_fitness\", pop_max, iter_num)\n                writer.add_scalar(\"Time/step_time\", step_time, iter_num)\n                writer.add_scalar(\"Time/cumulative\", cum_time, iter_num)\n                writer.add_scalar(\"EarlyStopping/no_improvement_count\", no_improvement_count, iter_num)\n                writer.add_scalar(\"EarlyStopping/relative_change_pct\", relative_change * 100, iter_num)\n                T_vals = [self._decode(ind)[0] for ind in parents]\n                alpha_vals = [self._decode(ind)[1] for ind in parents]\n                eta_vals = [self._decode(ind)[2] for ind in parents]\n                writer.add_histogram(\"Population/T_distribution\", np.array(T_vals), iter_num)\n                writer.add_histogram(\"Population/alpha_distribution\", np.array(alpha_vals), iter_num)\n                writer.add_histogram(\"Population/eta_distribution\", np.array(eta_vals), iter_num)\n                writer.add_histogram(\"Population/fitness_distribution\", np.array(vals), iter_num)\n                writer.add_scalar(\"Time/avg_step_time_running\", cum_time / iter_num, iter_num)\n            history.append({\n                \"iter\": s,\n                \"best_corpus_ppl_val\": best_metrics['corpus_ppl_val'],\n                \"best_corpus_ppl_train\": best_metrics.get('corpus_ppl_train', float('nan')),\n                \"best_doc_ppl_val_mean\": best_metrics['doc_ppl_val_mean'],\n                \"best_doc_ppl_val_var\": best_metrics.get('doc_ppl_val_var', float('nan')),\n                \"best_doc_ppl_val_max\": best_metrics['doc_ppl_val_max'],\n                \"best_doc_ppl_train_mean\": best_metrics.get('doc_ppl_train_mean', float('nan')),\n                \"best_doc_ppl_train_var\": best_metrics.get('doc_ppl_train_var', float('nan')),\n                \"pop_mean\": pop_mean,\n                \"pop_std\": pop_std,\n                \"pop_min\": pop_min,\n                \"pop_max\": pop_max,\n                \"T_best\": Tb,\n                \"alpha_best\": ab,\n                \"eta_best\": eb,\n                \"step_time\": step_time,\n                \"cum_time\": cum_time,\n                \"no_improvement_count\": no_improvement_count,\n                \"relative_change_pct\": relative_change * 100\n            })\n\n            if outdir:\n                self._save_population(parents, s + 1, outdir)\n\n            if no_improvement_count >= self.max_no_improvement:\n                print(f\"[ES] Early stopping: |Δ max(doc_ppl_val)|/prev ≤ {self.early_stop_eps_pct*100:.2f}% for {self.max_no_improvement} steps\")\n                break\n\n        final_cum_time = time.perf_counter() - t0\n        print(f\"[ES] Optimization complete! Total time: {final_cum_time:.2f}s\")\n        print(f\"[ES] Final best: T={Tb}, alpha={ab:.6f}, eta={eb:.6f}\")\n        print(f\"[ES]   corpus_ppl_val={best_metrics['corpus_ppl_val']:.4f}\")\n        print(f\"[ES]   doc_ppl_val_mean={best_metrics['doc_ppl_val_mean']:.4f}\")\n        if 'doc_ppl_val_var' in best_metrics:\n            print(f\"[ES]   doc_ppl_val_var={best_metrics['doc_ppl_val_var']:.4f}\")\n        print(f\"[ES]   doc_ppl_val_max={best_metrics['doc_ppl_val_max']:.4f}\")\n\n        best = self._decode(best_sofar)\n        return {\n            \"best\": {\n                \"T\": best[0],\n                \"alpha\": best[1],\n                \"eta\": best[2],\n                **best_metrics\n            },\n            \"history\": history,\n            \"total_time\": final_cum_time,\n            \"avg_step_time\": float(np.mean([h[\"step_time\"] for h in history])) if history else 0.0,\n            \"stopped_early\": no_improvement_count >= self.max_no_improvement\n        }\n",
   "metadata": {
    "id": "LCHio8DsqM9c",
    "ExecuteTime": {
     "end_time": "2025-10-26T15:51:48.317430Z",
     "start_time": "2025-10-26T15:51:48.221324Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "EVAL_CACHE = {}\n",
    "\n",
    "def _doc_perplexities(lda, X, batch_size=1024, eps=1e-300):\n",
    "    phi = lda.components_.astype(np.float64)\n",
    "    phi /= phi.sum(axis=1, keepdims=True)\n",
    "    n = X.shape[0]\n",
    "    out = np.empty(n, dtype=np.float64)\n",
    "    for s in range(0, n, batch_size):\n",
    "        e = min(n, s + batch_size)\n",
    "        Xb = X[s:e]\n",
    "        theta = lda.transform(Xb)\n",
    "        theta = np.clip(theta, 1e-12, None)\n",
    "        for i in range(Xb.shape[0]):\n",
    "            row = Xb[i]\n",
    "            idx = row.indices\n",
    "            dat = row.data\n",
    "            if dat.size == 0:\n",
    "                out[s + i] = 1.0\n",
    "                continue\n",
    "            p = theta[i].dot(phi[:, idx])\n",
    "            p = np.clip(p, eps, None)\n",
    "            ll = float((np.log(p) * dat).sum())\n",
    "            cnt = float(dat.sum())\n",
    "            out[s + i] = math.exp(-ll / max(cnt, 1.0))\n",
    "    return out\n",
    "\n",
    "def _fit_eval_full(T, alpha, eta, Xtr, Xva, seed=42, max_iter=400, batch_size=2048, learning_method=\"online\"):\n",
    "    key = (int(T), float(alpha), float(eta), int(seed), int(max_iter), int(batch_size), learning_method, id(Xtr), id(Xva))\n",
    "    if key in EVAL_CACHE:\n",
    "        return EVAL_CACHE[key]\n",
    "    print(f\"[LDA] Training LDA: T={T}, alpha={alpha:.6f}, eta={eta:.6f}\")\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=int(T),\n",
    "        doc_topic_prior=float(alpha),\n",
    "        topic_word_prior=float(eta),\n",
    "        learning_method=learning_method,\n",
    "        max_iter=int(max_iter),\n",
    "        batch_size=int(batch_size),\n",
    "        random_state=int(seed),\n",
    "        evaluate_every=-1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    t0 = time.perf_counter()\n",
    "    lda.fit(Xtr)\n",
    "    fit_time = time.perf_counter() - t0\n",
    "    print(f\"[LDA] Training completed in {fit_time:.2f}s (n_iter={getattr(lda, 'n_iter_', 'N/A')})\")\n",
    "    t1 = time.perf_counter()\n",
    "    corpus_ppl_val = float(lda.perplexity(Xva))\n",
    "    doc_ppl_val = _doc_perplexities(lda, Xva, batch_size=min(1024, Xva.shape[0]))\n",
    "    corpus_ppl_train = float(lda.perplexity(Xtr))\n",
    "    doc_ppl_train = _doc_perplexities(lda, Xtr, batch_size=min(1024, Xtr.shape[0]))\n",
    "    eval_time = time.perf_counter() - t1\n",
    "    print(f\"[LDA] Evaluation completed in {eval_time:.2f}s | Train ppl: {corpus_ppl_train:.4f}, Val ppl: {corpus_ppl_val:.4f}\")\n",
    "    res = {\n",
    "        \"T\": int(T),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"eta\": float(eta),\n",
    "        \"corpus_ppl_val\": corpus_ppl_val,\n",
    "        \"corpus_ppl_train\": corpus_ppl_train,\n",
    "        \"doc_ppl_val_mean\": float(np.mean(doc_ppl_val)),\n",
    "        \"doc_ppl_val_var\": float(np.var(doc_ppl_val)),\n",
    "        \"doc_ppl_val_max\": float(np.max(doc_ppl_val)),\n",
    "        \"doc_ppl_train_mean\": float(np.mean(doc_ppl_train)),\n",
    "        \"doc_ppl_train_var\": float(np.var(doc_ppl_train)),\n",
    "        \"doc_ppl_train_max\": float(np.max(doc_ppl_train)),\n",
    "        \"fit_time\": fit_time,\n",
    "        \"eval_time\": eval_time,\n",
    "        \"n_iter_lda\": getattr(lda, \"n_iter_\", None)\n",
    "    }\n",
    "    EVAL_CACHE[key] = res\n",
    "    return res\n",
    "\n",
    "def make_objective(Xtr, Xva, seed=42, max_iter=400, batch_size=2048, learning_method=\"online\"):\n",
    "    def objective(T, a, e):\n",
    "        r = _fit_eval_full(T, a, e, Xtr, Xva, seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
    "        return r[\"doc_ppl_val_mean\"]\n",
    "    return objective\n",
    "\n",
    "def make_eval_func(Xtr, Xva, seed=42, max_iter=400, batch_size=2048, learning_method=\"online\"):\n",
    "    def eval_func(T, a, e):\n",
    "        return _fit_eval_full(T, a, e, Xtr, Xva, seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
    "    return eval_func\n",
    "\n",
    "def _ensure_dir(p):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def _write_history_csv(history_rows, path):\n",
    "    if not history_rows:\n",
    "        return\n",
    "    fields = list(history_rows[0].keys())\n",
    "    with open(path, \"w\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fields)\n",
    "        w.writeheader()\n",
    "        for row in history_rows:\n",
    "            w.writerow(row)\n",
    "\n",
    "def _plot_series(xs, ys, xlabel, ylabel, title, path):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(xs, ys, marker=\"o\", linewidth=1.5)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "@timing_decorator\n",
    "def run_baseline(\n",
    "    algorithm_name,\n",
    "    optimizer_class,\n",
    "    Xtr,\n",
    "    Xva,\n",
    "    outdir,\n",
    "    dataset_name,\n",
    "    gens_or_steps=200,\n",
    "    pop_size=10,\n",
    "    seed=42,\n",
    "    max_iter=400,\n",
    "    batch_size=2048,\n",
    "    learning_method=\"online\",\n",
    "    **optimizer_kwargs\n",
    "):\n",
    "    _ensure_dir(outdir)\n",
    "    writer = SummaryWriter(log_dir=os.path.join(outdir, \"tensorboard\"))\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"[BASELINE] Running {algorithm_name} on {dataset_name}\")\n",
    "    print(f\"[BASELINE] Output directory: {outdir}\")\n",
    "    print(f\"[TensorBoard] Logging to {os.path.join(outdir, 'tensorboard')}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    obj = make_objective(Xtr, Xva, seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
    "    eval_func = make_eval_func(Xtr, Xva, seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
    "    optimizer = optimizer_class(obj, eval_func, seed=seed, **optimizer_kwargs)\n",
    "    if algorithm_name == \"GA\":\n",
    "        res = optimizer.run(gens=gens_or_steps, pop_size=pop_size, writer=writer, outdir=outdir)\n",
    "    else:\n",
    "        res = optimizer.run(steps=gens_or_steps, writer=writer, outdir=outdir)\n",
    "    writer.close()\n",
    "    print(f\"\\n[TensorBoard] TensorBoard logs saved. Run: tensorboard --logdir={os.path.join(outdir, 'tensorboard')}\")\n",
    "    _write_history_csv(res[\"history\"], os.path.join(outdir, \"history.csv\"))\n",
    "    if res[\"history\"]:\n",
    "        xs = [h[\"iter\"] for h in res[\"history\"]]\n",
    "        ys_val_mean = [h[\"best_doc_ppl_val_mean\"] for h in res[\"history\"]]\n",
    "        ys_val_max = [h[\"best_doc_ppl_val_max\"] for h in res[\"history\"]]\n",
    "        ys_val_var = [h.get(\"best_doc_ppl_val_var\", float(\"nan\")) for h in res[\"history\"]]\n",
    "        ys_corpus_val = [h[\"best_corpus_ppl_val\"] for h in res[\"history\"]]\n",
    "        ys_T = [h[\"T_best\"] for h in res[\"history\"]]\n",
    "        ys_step = [h[\"step_time\"] for h in res[\"history\"]]\n",
    "        _plot_series(xs, ys_val_mean, \"Iteration\", \"doc_ppl_val_mean\",\n",
    "                     f\"{algorithm_name}: Mean Doc Perplexity (Val) vs Iteration\",\n",
    "                     os.path.join(outdir, \"doc_ppl_val_mean.png\"))\n",
    "        _plot_series(xs, ys_val_max, \"Iteration\", \"doc_ppl_val_max\",\n",
    "                     f\"{algorithm_name}: Max Doc Perplexity (Val) vs Iteration\",\n",
    "                     os.path.join(outdir, \"doc_ppl_val_max.png\"))\n",
    "        _plot_series(xs, ys_val_var, \"Iteration\", \"doc_ppl_val_var\",\n",
    "                     f\"{algorithm_name}: Variance of Doc Perplexity (Val) vs Iteration\",\n",
    "                     os.path.join(outdir, \"doc_ppl_val_var.png\"))\n",
    "        _plot_series(xs, ys_corpus_val, \"Iteration\", \"corpus_ppl_val\",\n",
    "                     f\"{algorithm_name}: Corpus Perplexity (Val) vs Iteration\",\n",
    "                     os.path.join(outdir, \"corpus_ppl_val.png\"))\n",
    "        _plot_series(xs, ys_T, \"Iteration\", \"T\",\n",
    "                     f\"{algorithm_name}: Topics (T) vs Iteration\",\n",
    "                     os.path.join(outdir, \"T_over_time.png\"))\n",
    "        _plot_series(xs, ys_step, \"Iteration\", \"seconds\",\n",
    "                     f\"{algorithm_name}: Step Time vs Iteration\",\n",
    "                     os.path.join(outdir, \"step_time.png\"))\n",
    "    summary = {\n",
    "        \"algorithm\": algorithm_name,\n",
    "        \"dataset\": dataset_name,\n",
    "        \"best\": res[\"best\"],\n",
    "        \"avg_step_time\": res[\"avg_step_time\"],\n",
    "        \"total_time\": res[\"total_time\"],\n",
    "        \"stopped_early\": res.get(\"stopped_early\", False),\n",
    "        \"num_iterations\": len(res[\"history\"])\n",
    "    }\n",
    "    with open(os.path.join(outdir, \"summary.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"\\n[BASELINE] {algorithm_name} on {dataset_name} completed!\")\n",
    "    print(f\"[BASELINE] Best T: {res['best']['T']}, alpha: {res['best']['alpha']:.6f}, eta: {res['best']['eta']:.6f}\")\n",
    "    print(f\"[BASELINE] Best doc_ppl_val_mean: {res['best']['doc_ppl_val_mean']:.4f}\")\n",
    "    if 'doc_ppl_val_var' in res['best']:\n",
    "        print(f\"[BASELINE] Best doc_ppl_val_var: {res['best']['doc_ppl_val_var']:.4f}\")\n",
    "    print(f\"[BASELINE] Best doc_ppl_val_max: {res['best']['doc_ppl_val_max']:.4f}\")\n",
    "    print(f\"[BASELINE] Avg step time: {res['avg_step_time']:.2f}s, Total time: {res['total_time']:.2f}s\")\n",
    "    print(f\"[BASELINE] Stopped early: {res.get('stopped_early', False)}\\n\")\n",
    "    return summary"
   ],
   "metadata": {
    "id": "eE0uE7RHrloY",
    "ExecuteTime": {
     "end_time": "2025-10-26T15:52:20.350054Z",
     "start_time": "2025-10-26T15:52:20.336357Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "DATASETS = {\n    \"20news\": (\"data/X_20news_train_bow.npz\", \"data/X_20news_val_bow.npz\"),\n    \"agnews\": (\"data/X_agnews_train_bow.npz\", \"data/X_agnews_val_bow.npz\"),\n    \"val_out\": (\"data/X_val_out_train_bow.npz\", \"data/X_val_out_val_bow.npz\"),\n    \"yelp\": (\"data/X_yelp_train_bow.npz\", \"data/X_yelp_val_bow.npz\"),\n}\n\nBASE_DIR = \"runs\"\ngens_ga = 200\nsteps_es = 200\npop_size = 10\nelite = 5\nseed = 42\nbatch_size = 2048\nlearning_method = \"online\"\nearly_stop_eps_pct = 0.01\nmax_no_improvement = 5\n\nresults = {}\n\nprint(\"=\"*80)\nprint(\"EXPERIMENT 1: Single dataset (agnews) with max_iter=60\")\nprint(\"=\"*80)\n\n# First experiment: agnews with max_iter=60\nXtr_agnews, Xva_agnews = load_bow_pair(\n    \"data/X_agnews_train_bow.npz\", \n    \"data/X_agnews_val_bow.npz\"\n)\n\n# Run GA\nga_summary_exp1 = run_baseline(\n    \"GA\",\n    GAOptimizer,\n    Xtr_agnews,\n    Xva_agnews,\n    outdir=os.path.join(BASE_DIR, \"experiment_1_agnews_maxiter60\", \"ga\"),\n    dataset_name=\"agnews\",\n    gens_or_steps=gens_ga,\n    pop_size=pop_size,\n    seed=seed,\n    max_iter=60,\n    batch_size=batch_size,\n    learning_method=learning_method,\n    early_stop_eps_pct=early_stop_eps_pct,\n    max_no_improvement=max_no_improvement,\n    elite=elite\n)\n\n# Run ES\nes_summary_exp1 = run_baseline(\n    \"ES\",\n    ESOptimizer,\n    Xtr_agnews,\n    Xva_agnews,\n    outdir=os.path.join(BASE_DIR, \"experiment_1_agnews_maxiter60\", \"es\"),\n    dataset_name=\"agnews\",\n    gens_or_steps=steps_es,\n    pop_size=pop_size,\n    seed=seed,\n    max_iter=60,\n    batch_size=batch_size,\n    learning_method=learning_method,\n    early_stop_eps_pct=early_stop_eps_pct,\n    max_no_improvement=max_no_improvement\n)\n\nresults[\"experiment_1_agnews_maxiter60\"] = {\n    \"GA\": ga_summary_exp1,\n    \"ES\": es_summary_exp1\n}\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"EXPERIMENT 2: All datasets with max_iter=100\")\nprint(\"=\"*80)\n\n# Second experiment: all datasets with max_iter=100\nfor name, (tr_path, va_path) in DATASETS.items():\n    print(f\"\\n{'='*80}\")\n    print(f\"Processing dataset: {name}\")\n    print(f\"{'='*80}\")\n    \n    Xtr_loc, Xva_loc = load_bow_pair(tr_path, va_path)\n\n    # Run GA\n    ga_summary = run_baseline(\n        \"GA\",\n        GAOptimizer,\n        Xtr_loc,\n        Xva_loc,\n        outdir=os.path.join(BASE_DIR, \"experiment_2_global_maxiter100\", name, \"ga\"),\n        dataset_name=name,\n        gens_or_steps=gens_ga,\n        pop_size=pop_size,\n        seed=seed,\n        max_iter=100,\n        batch_size=batch_size,\n        learning_method=learning_method,\n        early_stop_eps_pct=early_stop_eps_pct,\n        max_no_improvement=max_no_improvement,\n        elite=elite\n    )\n\n    # Run ES\n    es_summary = run_baseline(\n        \"ES\",\n        ESOptimizer,\n        Xtr_loc,\n        Xva_loc,\n        outdir=os.path.join(BASE_DIR, \"experiment_2_global_maxiter100\", name, \"es\"),\n        dataset_name=name,\n        gens_or_steps=steps_es,\n        pop_size=pop_size,\n        seed=seed,\n        max_iter=100,\n        batch_size=batch_size,\n        learning_method=learning_method,\n        early_stop_eps_pct=early_stop_eps_pct,\n        max_no_improvement=max_no_improvement\n    )\n\n    results[f\"experiment_2_{name}_maxiter100\"] = {\n        \"GA\": ga_summary,\n        \"ES\": es_summary\n    }\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ALL EXPERIMENTS COMPLETED!\")\nprint(\"=\"*80)\nprint(json.dumps(results, indent=2, ensure_ascii=False))\n\n# Save final results\nwith open(os.path.join(BASE_DIR, \"all_experiments_results.json\"), \"w\") as f:\n    json.dump(results, f, indent=2, ensure_ascii=False)\n\nprint(f\"\\nResults saved to: {os.path.join(BASE_DIR, 'all_experiments_results.json')}\")\n",
   "metadata": {
    "id": "9IY9-TT8stTs"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}