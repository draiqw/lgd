{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### MAIN_CODE"
   ],
   "metadata": {
    "id": "Cg21VFN0JynV"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tiVGOw-T9pEy",
    "ExecuteTime": {
     "end_time": "2025-10-26T15:48:28.345836Z",
     "start_time": "2025-10-26T15:48:11.537708Z"
    }
   },
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from gensim.models import LdaModel\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, math\n",
    "import numpy as np\n",
    "from typing import Callable, Tuple, Dict, List\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "def load_bow_pair(train_path: str, val_path: str):\n",
    "    Xtr = sp.load_npz(train_path).tocsr(copy=False)\n",
    "    Xva = sp.load_npz(val_path).tocsr(copy=False)\n",
    "    return Xtr, Xva"
   ],
   "metadata": {
    "id": "VYDIrQLj-enq"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Xtr, Xva = load_bow_pair(\"X_agnews_train_bow.npz\", \"X_agnews_val_bow.npz\")"
   ],
   "metadata": {
    "id": "grnTmfsTBDFL"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def lda_blackbox(\n",
    "    T: int,\n",
    "    alpha: float,\n",
    "    eta: float,\n",
    "    *,\n",
    "    seed: int = 42,\n",
    "    max_iter: int = 400,\n",
    "    batch_size: int = 2048,\n",
    "    learning_method: str = \"online\"\n",
    "):\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=int(T),\n",
    "        doc_topic_prior=float(alpha),\n",
    "        topic_word_prior=float(eta),\n",
    "        learning_method=learning_method,\n",
    "        max_iter=int(max_iter),\n",
    "        batch_size=int(batch_size),\n",
    "        random_state=int(seed),\n",
    "        evaluate_every=-1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    t0 = time.perf_counter()\n",
    "    lda.fit(Xtr)\n",
    "    fit_time = time.perf_counter() - t0\n",
    "    ppl = float(lda.perplexity(Xva))\n",
    "    return ppl"
   ],
   "metadata": {
    "id": "CKTS0AMIpP8O"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "try:\n",
    "    creator.FitnessMin\n",
    "except Exception:\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "try:\n",
    "    creator.Individual\n",
    "except Exception:\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)"
   ],
   "metadata": {
    "id": "KoQZPMccqB4V"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def _clamp(x, lo, hi):\n",
    "    return lo if x < lo else hi if x > hi else x"
   ],
   "metadata": {
    "id": "s7y7cFkCqFhZ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class GAOptimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        obj,\n",
    "        T_bounds=(10, 200),\n",
    "        alpha_bounds=(1e-3, 1.0),\n",
    "        eta_bounds=(1e-3, 1.0),\n",
    "        *,\n",
    "        log_space=True,\n",
    "        seed=42,\n",
    "        cxpb=0.9,\n",
    "        mutpb=0.2,\n",
    "        tournsize=3,\n",
    "        elite=2,\n",
    "        sigma_log=0.25,\n",
    "        dT=5\n",
    "    ):\n",
    "        self.obj = obj\n",
    "        self.Tb = T_bounds\n",
    "        self.ab = alpha_bounds\n",
    "        self.eb = eta_bounds\n",
    "        self.log = log_space\n",
    "        self.seed = int(seed)\n",
    "        self.cxpb = cxpb\n",
    "        self.mutpb = mutpb\n",
    "        self.tournsize = tournsize\n",
    "        self.elite = elite\n",
    "        self.sigma_log = sigma_log\n",
    "        self.dT = int(dT)\n",
    "        self.toolbox = base.Toolbox()\n",
    "        if self.log:\n",
    "            self._ab_log = (math.log10(self.ab[0]), math.log10(self.ab[1]))\n",
    "            self._eb_log = (math.log10(self.eb[0]), math.log10(self.eb[1]))\n",
    "        else:\n",
    "            self._ab_log = self.ab\n",
    "            self._eb_log = self.eb\n",
    "        random.seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        self.toolbox.register(\"attr_T\", random.randint, self.Tb[0], self.Tb[1])\n",
    "        self.toolbox.register(\"attr_a\", random.uniform, self._ab_log[0], self._ab_log[1])\n",
    "        self.toolbox.register(\"attr_e\", random.uniform, self._eb_log[0], self._eb_log[1])\n",
    "        self.toolbox.register(\"individual\", tools.initCycle, creator.Individual, (self.toolbox.attr_T, self.toolbox.attr_a, self.toolbox.attr_e), n=1)\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        self.toolbox.register(\"evaluate\", self._evaluate)\n",
    "        self.toolbox.register(\"select\", tools.selTournament, tournsize=self.tournsize)\n",
    "\n",
    "    def _decode(self, ind):\n",
    "        T = int(round(ind[0]))\n",
    "        T = _clamp(T, self.Tb[0], self.Tb[1])\n",
    "        if self.log:\n",
    "            a = 10.0 ** _clamp(ind[1], self._ab_log[0], self._ab_log[1])\n",
    "            e = 10.0 ** _clamp(ind[2], self._eb_log[0], self._eb_log[1])\n",
    "        else:\n",
    "            a = _clamp(ind[1], self.ab[0], self.ab[1])\n",
    "            e = _clamp(ind[2], self.eb[0], self.eb[1])\n",
    "        return T, float(a), float(e)\n",
    "\n",
    "    def _evaluate(self, ind):\n",
    "        T, a, e = self._decode(ind)\n",
    "        try:\n",
    "            v = float(self.obj(T, a, e))\n",
    "        except Exception:\n",
    "            v = float(\"inf\")\n",
    "        return (v,)\n",
    "\n",
    "    def _cx(self, ind1, ind2):\n",
    "        if random.random() < 0.5:\n",
    "            ind1[0], ind2[0] = ind2[0], ind1[0]\n",
    "        for j in (1, 2):\n",
    "            g = random.random()\n",
    "            a = ind1[j]\n",
    "            b = ind2[j]\n",
    "            ind1[j] = g * a + (1.0 - g) * b\n",
    "            ind2[j] = (1.0 - g) * a + g * b\n",
    "        return ind1, ind2\n",
    "\n",
    "    def _mut(self, ind):\n",
    "        if random.random() < 1.0:\n",
    "            ind[0] = _clamp(int(round(ind[0] + random.randint(-self.dT, self.dT))), self.Tb[0], self.Tb[1])\n",
    "        if random.random() < 1.0:\n",
    "            ind[1] = _clamp(ind[1] + random.gauss(0.0, self.sigma_log), self._ab_log[0], self._ab_log[1])\n",
    "        if random.random() < 1.0:\n",
    "            ind[2] = _clamp(ind[2] + random.gauss(0.0, self.sigma_log), self._eb_log[0], self._eb_log[1])\n",
    "        return (ind,)\n",
    "\n",
    "    def run(self, gens=20, pop_size=24):\n",
    "        pop = self.toolbox.population(n=pop_size)\n",
    "        hall = tools.HallOfFame(maxsize=self.elite)\n",
    "        history = []\n",
    "        t0 = time.perf_counter()\n",
    "        cum_time = 0.0\n",
    "        for ind in pop:\n",
    "            ind.fitness.values = self.toolbox.evaluate(ind)\n",
    "        hall.update(pop)\n",
    "        best_sofar = min(pop, key=lambda x: x.fitness.values[0])\n",
    "        for g in range(gens):\n",
    "            gs = time.perf_counter()\n",
    "            elites = tools.selBest(pop, self.elite)\n",
    "            offspring = self.toolbox.select(pop, len(pop) - self.elite)\n",
    "            offspring = list(map(self.toolbox.clone, offspring))\n",
    "            for i in range(0, len(offspring) - 1, 2):\n",
    "                if random.random() < self.cxpb:\n",
    "                    self._cx(offspring[i], offspring[i + 1])\n",
    "            for i in range(len(offspring)):\n",
    "                if random.random() < self.mutpb:\n",
    "                    self._mut(offspring[i])\n",
    "                del offspring[i].fitness.values\n",
    "            invalid = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            for ind in invalid:\n",
    "                ind.fitness.values = self.toolbox.evaluate(ind)\n",
    "            pop = elites + offspring\n",
    "            hall.update(pop)\n",
    "            cur_best = min(pop, key=lambda x: x.fitness.values[0])\n",
    "            if cur_best.fitness.values[0] < best_sofar.fitness.values[0]:\n",
    "                best_sofar = cur_best\n",
    "            gen_time = time.perf_counter() - gs\n",
    "            cum_time = time.perf_counter() - t0\n",
    "            vals = [ind.fitness.values[0] for ind in pop]\n",
    "            Tb, ab, eb = self._decode(best_sofar)\n",
    "            history.append({\n",
    "                \"iter\": g,\n",
    "                \"best_ppl_sofar\": best_sofar.fitness.values[0],\n",
    "                \"pop_mean\": float(np.mean(vals)),\n",
    "                \"pop_std\": float(np.std(vals)),\n",
    "                \"T_best\": Tb,\n",
    "                \"alpha_best\": ab,\n",
    "                \"eta_best\": eb,\n",
    "                \"step_time\": gen_time,\n",
    "                \"cum_time\": cum_time\n",
    "            })\n",
    "        best = self._decode(best_sofar)\n",
    "        best_val = best_sofar.fitness.values[0]\n",
    "        final_T = best[0]\n",
    "        first_hit = None\n",
    "        for row in history:\n",
    "            if row[\"T_best\"] == final_T:\n",
    "                first_hit = row[\"cum_time\"]\n",
    "                break\n",
    "        return {\n",
    "            \"best\": {\"T\": best[0], \"alpha\": best[1], \"eta\": best[2], \"ppl\": best_val},\n",
    "            \"history\": history,\n",
    "            \"total_time\": history[-1][\"cum_time\"] if history else 0.0,\n",
    "            \"time_to_best_T\": first_hit if first_hit is not None else None\n",
    "        }"
   ],
   "metadata": {
    "id": "4Kdm9lmmqJf1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class ESOptimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        obj,\n",
    "        T_bounds=(10, 200),\n",
    "        alpha_bounds=(1e-3, 1.0),\n",
    "        eta_bounds=(1e-3, 1.0),\n",
    "        *,\n",
    "        log_space=True,\n",
    "        seed=42,\n",
    "        mu=12,\n",
    "        lmbda=48,\n",
    "        sigma_log=0.25,\n",
    "        dT=5\n",
    "    ):\n",
    "        self.obj = obj\n",
    "        self.Tb = T_bounds\n",
    "        self.ab = alpha_bounds\n",
    "        self.eb = eta_bounds\n",
    "        self.log = log_space\n",
    "        self.seed = int(seed)\n",
    "        self.mu = int(mu)\n",
    "        self.lmbda = int(lmbda)\n",
    "        self.sigma_log = sigma_log\n",
    "        self.dT = int(dT)\n",
    "        self.toolbox = base.Toolbox()\n",
    "        if self.log:\n",
    "            self._ab_log = (math.log10(self.ab[0]), math.log10(self.ab[1]))\n",
    "            self._eb_log = (math.log10(self.eb[0]), math.log10(self.eb[1]))\n",
    "        else:\n",
    "            self._ab_log = self.ab\n",
    "            self._eb_log = self.eb\n",
    "        random.seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        self.toolbox.register(\"attr_T\", random.randint, self.Tb[0], self.Tb[1])\n",
    "        self.toolbox.register(\"attr_a\", random.uniform, self._ab_log[0], self._ab_log[1])\n",
    "        self.toolbox.register(\"attr_e\", random.uniform, self._eb_log[0], self._eb_log[1])\n",
    "        self.toolbox.register(\"individual\", tools.initCycle, creator.Individual, (self.toolbox.attr_T, self.toolbox.attr_a, self.toolbox.attr_e), n=1)\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        self.toolbox.register(\"evaluate\", self._evaluate)\n",
    "\n",
    "    def _clamp(self, ind):\n",
    "        ind[0] = _clamp(int(round(ind[0])), self.Tb[0], self.Tb[1])\n",
    "        ind[1] = _clamp(ind[1], self._ab_log[0], self._ab_log[1])\n",
    "        ind[2] = _clamp(ind[2], self._eb_log[0], self._eb_log[1])\n",
    "\n",
    "    def _decode(self, ind):\n",
    "        T = int(round(ind[0]))\n",
    "        T = _clamp(T, self.Tb[0], self.Tb[1])\n",
    "        if self.log:\n",
    "            a = 10.0 ** _clamp(ind[1], self._ab_log[0], self._ab_log[1])\n",
    "            e = 10.0 ** _clamp(ind[2], self._eb_log[0], self._eb_log[1])\n",
    "        else:\n",
    "            a = _clamp(ind[1], self.ab[0], self.ab[1])\n",
    "            e = _clamp(ind[2], self.eb[0], self.eb[1])\n",
    "        return T, float(a), float(e)\n",
    "\n",
    "    def _evaluate(self, ind):\n",
    "        T, a, e = self._decode(ind)\n",
    "        try:\n",
    "            v = float(self.obj(T, a, e))\n",
    "        except Exception:\n",
    "            v = float(\"inf\")\n",
    "        return (v,)\n",
    "\n",
    "    def _mut(self, parent):\n",
    "        child = creator.Individual(parent[:])\n",
    "        child[0] = int(round(child[0] + random.randint(-self.dT, self.dT)))\n",
    "        child[1] = child[1] + random.gauss(0.0, self.sigma_log)\n",
    "        child[2] = child[2] + random.gauss(0.0, self.sigma_log)\n",
    "        self._clamp(child)\n",
    "        return child\n",
    "\n",
    "    def run(self, steps=24):\n",
    "        parents = self.toolbox.population(n=self.mu)\n",
    "        history = []\n",
    "        t0 = time.perf_counter()\n",
    "        cum_time = 0.0\n",
    "        for ind in parents:\n",
    "            ind.fitness.values = self.toolbox.evaluate(ind)\n",
    "        best_sofar = min(parents, key=lambda x: x.fitness.values[0])\n",
    "        for s in range(steps):\n",
    "            gs = time.perf_counter()\n",
    "            off = []\n",
    "            for _ in range(self.lmbda):\n",
    "                p = random.choice(parents)\n",
    "                c = self._mut(p)\n",
    "                c.fitness.values = self.toolbox.evaluate(c)\n",
    "                off.append(c)\n",
    "            pool = parents + off\n",
    "            pool.sort(key=lambda x: x.fitness.values[0])\n",
    "            parents = [creator.Individual(ind[:]) for ind in pool[:self.mu]]\n",
    "            for i in range(self.mu):\n",
    "                parents[i].fitness.values = pool[i].fitness.values\n",
    "            cur_best = parents[0]\n",
    "            if cur_best.fitness.values[0] < best_sofar.fitness.values[0]:\n",
    "                best_sofar = cur_best\n",
    "            step_time = time.perf_counter() - gs\n",
    "            cum_time = time.perf_counter() - t0\n",
    "            vals = [ind.fitness.values[0] for ind in parents]\n",
    "            Tb, ab, eb = self._decode(best_sofar)\n",
    "            history.append({\n",
    "                \"iter\": s,\n",
    "                \"best_ppl_sofar\": best_sofar.fitness.values[0],\n",
    "                \"pop_mean\": float(np.mean(vals)),\n",
    "                \"pop_std\": float(np.std(vals)),\n",
    "                \"T_best\": Tb,\n",
    "                \"alpha_best\": ab,\n",
    "                \"eta_best\": eb,\n",
    "                \"step_time\": step_time,\n",
    "                \"cum_time\": cum_time\n",
    "            })\n",
    "        best = self._decode(best_sofar)\n",
    "        best_val = best_sofar.fitness.values[0]\n",
    "        final_T = best[0]\n",
    "        first_hit = None\n",
    "        for row in history:\n",
    "            if row[\"T_best\"] == final_T:\n",
    "                first_hit = row[\"cum_time\"]\n",
    "                break\n",
    "        return {\n",
    "            \"best\": {\"T\": best[0], \"alpha\": best[1], \"eta\": best[2], \"ppl\": best_val},\n",
    "            \"history\": history,\n",
    "            \"total_time\": history[-1][\"cum_time\"] if history else 0.0,\n",
    "            \"time_to_best_T\": first_hit if first_hit is not None else None\n",
    "        }"
   ],
   "metadata": {
    "id": "LCHio8DsqM9c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "EVAL_CACHE = {}\n",
    "\n",
    "def _doc_perplexities(lda, X, batch_size=1024, eps=1e-300):\n",
    "    phi = lda.components_.astype(np.float64)\n",
    "    phi /= phi.sum(axis=1, keepdims=True)\n",
    "    n = X.shape[0]\n",
    "    out = np.empty(n, dtype=np.float64)\n",
    "    for s in range(0, n, batch_size):\n",
    "        e = min(n, s + batch_size)\n",
    "        Xb = X[s:e]\n",
    "        theta = lda.transform(Xb)\n",
    "        theta = np.clip(theta, 1e-12, None)\n",
    "        for i in range(Xb.shape[0]):\n",
    "            row = Xb[i]\n",
    "            idx = row.indices\n",
    "            dat = row.data\n",
    "            if dat.size == 0:\n",
    "                out[s + i] = 1.0\n",
    "                continue\n",
    "            p = theta[i].dot(phi[:, idx])\n",
    "            p = np.clip(p, eps, None)\n",
    "            ll = float((np.log(p) * dat).sum())\n",
    "            cnt = float(dat.sum())\n",
    "            out[s + i] = math.exp(-ll / max(cnt, 1.0))\n",
    "    return out\n",
    "\n",
    "def _fit_eval_full(T, alpha, eta, seed=42, max_iter=400, batch_size=2048, learning_method=\"online\"):\n",
    "    key = (int(T), float(alpha), float(eta), int(seed), int(max_iter), int(batch_size), learning_method)\n",
    "    if key in EVAL_CACHE:\n",
    "        return EVAL_CACHE[key]\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=int(T),\n",
    "        doc_topic_prior=float(alpha),\n",
    "        topic_word_prior=float(eta),\n",
    "        learning_method=learning_method,\n",
    "        max_iter=int(max_iter),\n",
    "        batch_size=int(batch_size),\n",
    "        random_state=int(seed),\n",
    "        evaluate_every=-1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    t0 = time.perf_counter()\n",
    "    lda.fit(Xtr)\n",
    "    fit_time = time.perf_counter() - t0\n",
    "    t1 = time.perf_counter()\n",
    "    corpus_ppl = float(lda.perplexity(Xva))\n",
    "    doc_ppl = _doc_perplexities(lda, Xva, batch_size=min(1024, Xva.shape[0]))\n",
    "    eval_time = time.perf_counter() - t1\n",
    "    res = {\n",
    "        \"T\": int(T),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"eta\": float(eta),\n",
    "        \"corpus_ppl\": corpus_ppl,\n",
    "        \"doc_ppl_mean\": float(np.mean(doc_ppl)),\n",
    "        \"doc_ppl_max\": float(np.max(doc_ppl)),\n",
    "        \"fit_time\": fit_time,\n",
    "        \"eval_time\": eval_time,\n",
    "        \"n_iter_lda\": getattr(lda, \"n_iter_\", None)\n",
    "    }\n",
    "    EVAL_CACHE[key] = res\n",
    "    return res\n",
    "\n",
    "def make_objective(seed=42, max_iter=400, batch_size=2048, learning_method=\"online\"):\n",
    "    def objective(T, a, e):\n",
    "        r = _fit_eval_full(T, a, e, seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
    "        return r[\"corpus_ppl\"]\n",
    "    return objective\n",
    "\n",
    "def _ensure_dir(p):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def _write_history_csv(history_rows, path):\n",
    "    fields = [\"iter\",\"best_corpus_ppl\",\"best_doc_ppl_max\",\"pop_mean\",\"pop_std\",\"T_best\",\"alpha_best\",\"eta_best\",\"step_time\",\"cum_time\"]\n",
    "    with open(path, \"w\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fields)\n",
    "        w.writeheader()\n",
    "        for row in history_rows:\n",
    "            w.writerow(row)\n",
    "\n",
    "def _plot_series(xs, ys, xlabel, ylabel, title, path):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(xs, ys, marker=\"o\", linewidth=1.5)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def run_ga_with_logging(\n",
    "    outdir,\n",
    "    gens=24,\n",
    "    pop_size=24,\n",
    "    T_bounds=(10,200),\n",
    "    alpha_bounds=(1e-3,1.0),\n",
    "    eta_bounds=(1e-3,1.0),\n",
    "    seed=42,\n",
    "    max_iter=400,\n",
    "    batch_size=2048,\n",
    "    learning_method=\"online\",\n",
    "    cxpb=0.9,\n",
    "    mutpb=0.2,\n",
    "    tournsize=3,\n",
    "    elite=2,\n",
    "    sigma_log=0.25,\n",
    "    dT=5\n",
    "):\n",
    "    _ensure_dir(outdir)\n",
    "    obj = make_objective(seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
    "    ga = GAOptimizer(\n",
    "        obj,\n",
    "        T_bounds=T_bounds,\n",
    "        alpha_bounds=alpha_bounds,\n",
    "        eta_bounds=eta_bounds,\n",
    "        log_space=True,\n",
    "        seed=seed,\n",
    "        cxpb=cxpb,\n",
    "        mutpb=mutpb,\n",
    "        tournsize=tournsize,\n",
    "        elite=elite,\n",
    "        sigma_log=sigma_log,\n",
    "        dT=dT\n",
    "    )\n",
    "    res = ga.run(gens=gens, pop_size=pop_size)\n",
    "    hist = []\n",
    "    for row in res[\"history\"]:\n",
    "        T = row[\"T_best\"]\n",
    "        a = row[\"alpha_best\"]\n",
    "        e = row[\"eta_best\"]\n",
    "        r = _fit_eval_full(T, a, e, seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
    "        hist.append({\n",
    "            \"iter\": row[\"iter\"],\n",
    "            \"best_corpus_ppl\": float(r[\"corpus_ppl\"]),\n",
    "            \"best_doc_ppl_max\": float(r[\"doc_ppl_max\"]),\n",
    "            \"pop_mean\": row[\"pop_mean\"],\n",
    "            \"pop_std\": row[\"pop_std\"],\n",
    "            \"T_best\": int(T),\n",
    "            \"alpha_best\": float(a),\n",
    "            \"eta_best\": float(e),\n",
    "            \"step_time\": row[\"step_time\"],\n",
    "            \"cum_time\": row[\"cum_time\"]\n",
    "        })\n",
    "    _write_history_csv(hist, os.path.join(outdir, \"history.csv\"))\n",
    "    xs = [h[\"iter\"] for h in hist]\n",
    "    ys_mean = [h[\"best_corpus_ppl\"] for h in hist]\n",
    "    ys_max = [h[\"best_doc_ppl_max\"] for h in hist]\n",
    "    _plot_series(xs, ys_mean, \"iter\", \"perplexity\", \"GA: mean perplexity vs iter\", os.path.join(outdir, \"mean_ppl.png\"))\n",
    "    _plot_series(xs, ys_max, \"iter\", \"perplexity\", \"GA: max doc perplexity vs iter\", os.path.join(outdir, \"max_ppl.png\"))\n",
    "    avg_step_time = float(np.mean([h[\"step_time\"] for h in hist])) if hist else 0.0\n",
    "    summary = {\n",
    "        \"best\": res[\"best\"],\n",
    "        \"avg_step_time\": avg_step_time,\n",
    "        \"total_time\": res[\"total_time\"],\n",
    "        \"time_to_best_T\": res[\"time_to_best_T\"]\n",
    "    }\n",
    "    with open(os.path.join(outdir, \"summary.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    return {\"history\": hist, \"summary\": summary}\n",
    "\n",
    "def run_es_with_logging(\n",
    "    outdir,\n",
    "    steps=24,\n",
    "    T_bounds=(10,200),\n",
    "    alpha_bounds=(1e-3,1.0),\n",
    "    eta_bounds=(1e-3,1.0),\n",
    "    seed=42,\n",
    "    max_iter=400,\n",
    "    batch_size=2048,\n",
    "    learning_method=\"online\",\n",
    "    mu=12,\n",
    "    lmbda=48,\n",
    "    sigma_log=0.25,\n",
    "    dT=5\n",
    "):\n",
    "    _ensure_dir(outdir)\n",
    "    obj = make_objective(seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
    "    es = ESOptimizer(\n",
    "        obj,\n",
    "        T_bounds=T_bounds,\n",
    "        alpha_bounds=alpha_bounds,\n",
    "        eta_bounds=eta_bounds,\n",
    "        log_space=True,\n",
    "        seed=seed,\n",
    "        mu=mu,\n",
    "        lmbda=lmbda,\n",
    "        sigma_log=sigma_log,\n",
    "        dT=dT\n",
    "    )\n",
    "    res = es.run(steps=steps)\n",
    "    hist = []\n",
    "    for row in res[\"history\"]:\n",
    "        T = row[\"T_best\"]\n",
    "        a = row[\"alpha_best\"]\n",
    "        e = row[\"eta_best\"]\n",
    "        r = _fit_eval_full(T, a, e, seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
    "        hist.append({\n",
    "            \"iter\": row[\"iter\"],\n",
    "            \"best_corpus_ppl\": float(r[\"corpus_ppl\"]),\n",
    "            \"best_doc_ppl_max\": float(r[\"doc_ppl_max\"]),\n",
    "            \"pop_mean\": row[\"pop_mean\"],\n",
    "            \"pop_std\": row[\"pop_std\"],\n",
    "            \"T_best\": int(T),\n",
    "            \"alpha_best\": float(a),\n",
    "            \"eta_best\": float(e),\n",
    "            \"step_time\": row[\"step_time\"],\n",
    "            \"cum_time\": row[\"cum_time\"]\n",
    "        })\n",
    "    _write_history_csv(hist, os.path.join(outdir, \"history.csv\"))\n",
    "    xs = [h[\"iter\"] for h in hist]\n",
    "    ys_mean = [h[\"best_corpus_ppl\"] for h in hist]\n",
    "    ys_max = [h[\"best_doc_ppl_max\"] for h in hist]\n",
    "    _plot_series(xs, ys_mean, \"iter\", \"perplexity\", \"ES: mean perplexity vs iter\", os.path.join(outdir, \"mean_ppl.png\"))\n",
    "    _plot_series(xs, ys_max, \"iter\", \"perplexity\", \"ES: max doc perplexity vs iter\", os.path.join(outdir, \"max_ppl.png\"))\n",
    "    avg_step_time = float(np.mean([h[\"step_time\"] for h in hist])) if hist else 0.0\n",
    "    summary = {\n",
    "        \"best\": res[\"best\"],\n",
    "        \"avg_step_time\": avg_step_time,\n",
    "        \"total_time\": res[\"total_time\"],\n",
    "        \"time_to_best_T\": res[\"time_to_best_T\"]\n",
    "    }\n",
    "    with open(os.path.join(outdir, \"summary.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    return {\"history\": hist, \"summary\": summary}\n"
   ],
   "metadata": {
    "id": "eE0uE7RHrloY"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "BASE_DIR = \"runs/agnews\"\n",
    "\n",
    "ga_out = run_ga_with_logging(\n",
    "    outdir=f\"{BASE_DIR}/ga\",\n",
    "    gens=24,\n",
    "    pop_size=24,\n",
    "    seed=42,\n",
    "    max_iter=400,\n",
    "    batch_size=2048,\n",
    "    learning_method=\"online\"\n",
    ")\n",
    "\n",
    "es_out = run_es_with_logging(\n",
    "    outdir=f\"{BASE_DIR}/es\",\n",
    "    steps=24,\n",
    "    seed=42,\n",
    "    max_iter=400,\n",
    "    batch_size=2048,\n",
    "    learning_method=\"online\"\n",
    ")\n",
    "\n",
    "print(\"GA summary:\", ga_out[\"summary\"])\n",
    "print(\"ES summary:\", es_out[\"summary\"])"
   ],
   "metadata": {
    "id": "9IY9-TT8stTs"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
