{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install deap\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0Dt4Td4_Ul2",
        "outputId": "3a07f337-6f54-49bb-de71-6401ff7ea6c8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Requirement already satisfied: deap in /usr/local/lib/python3.12/dist-packages (1.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from deap) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAIN_CODE"
      ],
      "metadata": {
        "id": "Cg21VFN0JynV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "tiVGOw-T9pEy"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from gensim.models import LdaModel\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time, math\n",
        "import numpy as np\n",
        "from typing import Callable, Tuple, Dict, List\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "from deap import base, creator, tools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_bow_pair(train_path: str, val_path: str):\n",
        "    Xtr = sp.load_npz(train_path).tocsr(copy=False)\n",
        "    Xva = sp.load_npz(val_path).tocsr(copy=False)\n",
        "    return Xtr, Xva"
      ],
      "metadata": {
        "id": "VYDIrQLj-enq"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr, Xva = load_bow_pair(\"X_agnews_train_bow.npz\", \"X_agnews_val_bow.npz\")"
      ],
      "metadata": {
        "id": "grnTmfsTBDFL"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lda_blackbox(\n",
        "    T: int,\n",
        "    alpha: float,\n",
        "    eta: float,\n",
        "    *,\n",
        "    seed: int = 42,\n",
        "    max_iter: int = 400,\n",
        "    batch_size: int = 2048,\n",
        "    learning_method: str = \"online\"\n",
        "):\n",
        "    if T < 2:\n",
        "        raise ValueError(\"T must be >= 2\")\n",
        "    if alpha <= 0 or eta <= 0:\n",
        "        raise ValueError(\"alpha and eta must be > 0\")\n",
        "    lda = LatentDirichletAllocation(\n",
        "        n_components=int(T),\n",
        "        doc_topic_prior=float(alpha),\n",
        "        topic_word_prior=float(eta),\n",
        "        learning_method=learning_method,\n",
        "        max_iter=int(max_iter),\n",
        "        batch_size=int(batch_size),\n",
        "        random_state=int(seed),\n",
        "        evaluate_every=-1,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    t0 = time.perf_counter()\n",
        "    lda.fit(Xtr)\n",
        "    fit_time = time.perf_counter() - t0\n",
        "    ppl = float(lda.perplexity(Xva))\n",
        "    return ppl"
      ],
      "metadata": {
        "id": "CKTS0AMIpP8O"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    creator.FitnessMin\n",
        "except Exception:\n",
        "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "try:\n",
        "    creator.Individual\n",
        "except Exception:\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)"
      ],
      "metadata": {
        "id": "KoQZPMccqB4V"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _clamp(x, lo, hi):\n",
        "    return lo if x < lo else hi if x > hi else x"
      ],
      "metadata": {
        "id": "s7y7cFkCqFhZ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAOptimizer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        obj,\n",
        "        T_bounds=(10, 200),\n",
        "        alpha_bounds=(1e-3, 1.0),\n",
        "        eta_bounds=(1e-3, 1.0),\n",
        "        *,\n",
        "        log_space=True,\n",
        "        seed=42,\n",
        "        cxpb=0.9,\n",
        "        mutpb=0.2,\n",
        "        tournsize=3,\n",
        "        elite=2,\n",
        "        sigma_log=0.25,\n",
        "        dT=5\n",
        "    ):\n",
        "        self.obj = obj\n",
        "        self.Tb = T_bounds\n",
        "        self.ab = alpha_bounds\n",
        "        self.eb = eta_bounds\n",
        "        self.log = log_space\n",
        "        self.seed = int(seed)\n",
        "        self.cxpb = cxpb\n",
        "        self.mutpb = mutpb\n",
        "        self.tournsize = tournsize\n",
        "        self.elite = elite\n",
        "        self.sigma_log = sigma_log\n",
        "        self.dT = int(dT)\n",
        "        self.toolbox = base.Toolbox()\n",
        "        if self.log:\n",
        "            self._ab_log = (math.log10(self.ab[0]), math.log10(self.ab[1]))\n",
        "            self._eb_log = (math.log10(self.eb[0]), math.log10(self.eb[1]))\n",
        "        else:\n",
        "            self._ab_log = self.ab\n",
        "            self._eb_log = self.eb\n",
        "        random.seed(self.seed)\n",
        "        np.random.seed(self.seed)\n",
        "        self.toolbox.register(\"attr_T\", random.randint, self.Tb[0], self.Tb[1])\n",
        "        self.toolbox.register(\"attr_a\", random.uniform, self._ab_log[0], self._ab_log[1])\n",
        "        self.toolbox.register(\"attr_e\", random.uniform, self._eb_log[0], self._eb_log[1])\n",
        "        self.toolbox.register(\"individual\", tools.initCycle, creator.Individual, (self.toolbox.attr_T, self.toolbox.attr_a, self.toolbox.attr_e), n=1)\n",
        "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
        "        self.toolbox.register(\"evaluate\", self._evaluate)\n",
        "        self.toolbox.register(\"select\", tools.selTournament, tournsize=self.tournsize)\n",
        "\n",
        "    def _decode(self, ind):\n",
        "        T = int(round(ind[0]))\n",
        "        T = _clamp(T, self.Tb[0], self.Tb[1])\n",
        "        if self.log:\n",
        "            a = 10.0 ** _clamp(ind[1], self._ab_log[0], self._ab_log[1])\n",
        "            e = 10.0 ** _clamp(ind[2], self._eb_log[0], self._eb_log[1])\n",
        "        else:\n",
        "            a = _clamp(ind[1], self.ab[0], self.ab[1])\n",
        "            e = _clamp(ind[2], self.eb[0], self.eb[1])\n",
        "        return T, float(a), float(e)\n",
        "\n",
        "    def _evaluate(self, ind):\n",
        "        T, a, e = self._decode(ind)\n",
        "        try:\n",
        "            v = float(self.obj(T, a, e))\n",
        "        except Exception:\n",
        "            v = float(\"inf\")\n",
        "        return (v,)\n",
        "\n",
        "    def _cx(self, ind1, ind2):\n",
        "        if random.random() < 0.5:\n",
        "            ind1[0], ind2[0] = ind2[0], ind1[0]\n",
        "        for j in (1, 2):\n",
        "            g = random.random()\n",
        "            a = ind1[j]\n",
        "            b = ind2[j]\n",
        "            ind1[j] = g * a + (1.0 - g) * b\n",
        "            ind2[j] = (1.0 - g) * a + g * b\n",
        "        return ind1, ind2\n",
        "\n",
        "    def _mut(self, ind):\n",
        "        if random.random() < 1.0:\n",
        "            ind[0] = _clamp(int(round(ind[0] + random.randint(-self.dT, self.dT))), self.Tb[0], self.Tb[1])\n",
        "        if random.random() < 1.0:\n",
        "            ind[1] = _clamp(ind[1] + random.gauss(0.0, self.sigma_log), self._ab_log[0], self._ab_log[1])\n",
        "        if random.random() < 1.0:\n",
        "            ind[2] = _clamp(ind[2] + random.gauss(0.0, self.sigma_log), self._eb_log[0], self._eb_log[1])\n",
        "        return (ind,)\n",
        "\n",
        "    def run(self, gens=20, pop_size=24):\n",
        "        pop = self.toolbox.population(n=pop_size)\n",
        "        hall = tools.HallOfFame(maxsize=self.elite)\n",
        "        history = []\n",
        "        t0 = time.perf_counter()\n",
        "        cum_time = 0.0\n",
        "        for ind in pop:\n",
        "            ind.fitness.values = self.toolbox.evaluate(ind)\n",
        "        hall.update(pop)\n",
        "        best_sofar = min(pop, key=lambda x: x.fitness.values[0])\n",
        "        for g in range(gens):\n",
        "            gs = time.perf_counter()\n",
        "            elites = tools.selBest(pop, self.elite)\n",
        "            offspring = self.toolbox.select(pop, len(pop) - self.elite)\n",
        "            offspring = list(map(self.toolbox.clone, offspring))\n",
        "            for i in range(0, len(offspring) - 1, 2):\n",
        "                if random.random() < self.cxpb:\n",
        "                    self._cx(offspring[i], offspring[i + 1])\n",
        "            for i in range(len(offspring)):\n",
        "                if random.random() < self.mutpb:\n",
        "                    self._mut(offspring[i])\n",
        "                del offspring[i].fitness.values\n",
        "            invalid = [ind for ind in offspring if not ind.fitness.valid]\n",
        "            for ind in invalid:\n",
        "                ind.fitness.values = self.toolbox.evaluate(ind)\n",
        "            pop = elites + offspring\n",
        "            hall.update(pop)\n",
        "            cur_best = min(pop, key=lambda x: x.fitness.values[0])\n",
        "            if cur_best.fitness.values[0] < best_sofar.fitness.values[0]:\n",
        "                best_sofar = cur_best\n",
        "            gen_time = time.perf_counter() - gs\n",
        "            cum_time = time.perf_counter() - t0\n",
        "            vals = [ind.fitness.values[0] for ind in pop]\n",
        "            Tb, ab, eb = self._decode(best_sofar)\n",
        "            history.append({\n",
        "                \"iter\": g,\n",
        "                \"best_ppl_sofar\": best_sofar.fitness.values[0],\n",
        "                \"pop_mean\": float(np.mean(vals)),\n",
        "                \"pop_std\": float(np.std(vals)),\n",
        "                \"T_best\": Tb,\n",
        "                \"alpha_best\": ab,\n",
        "                \"eta_best\": eb,\n",
        "                \"step_time\": gen_time,\n",
        "                \"cum_time\": cum_time\n",
        "            })\n",
        "        best = self._decode(best_sofar)\n",
        "        best_val = best_sofar.fitness.values[0]\n",
        "        final_T = best[0]\n",
        "        first_hit = None\n",
        "        for row in history:\n",
        "            if row[\"T_best\"] == final_T:\n",
        "                first_hit = row[\"cum_time\"]\n",
        "                break\n",
        "        return {\n",
        "            \"best\": {\"T\": best[0], \"alpha\": best[1], \"eta\": best[2], \"ppl\": best_val},\n",
        "            \"history\": history,\n",
        "            \"total_time\": history[-1][\"cum_time\"] if history else 0.0,\n",
        "            \"time_to_best_T\": first_hit if first_hit is not None else None\n",
        "        }"
      ],
      "metadata": {
        "id": "4Kdm9lmmqJf1"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ESOptimizer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        obj,\n",
        "        T_bounds=(10, 200),\n",
        "        alpha_bounds=(1e-3, 1.0),\n",
        "        eta_bounds=(1e-3, 1.0),\n",
        "        *,\n",
        "        log_space=True,\n",
        "        seed=42,\n",
        "        mu=12,\n",
        "        lmbda=48,\n",
        "        sigma_log=0.25,\n",
        "        dT=5\n",
        "    ):\n",
        "        self.obj = obj\n",
        "        self.Tb = T_bounds\n",
        "        self.ab = alpha_bounds\n",
        "        self.eb = eta_bounds\n",
        "        self.log = log_space\n",
        "        self.seed = int(seed)\n",
        "        self.mu = int(mu)\n",
        "        self.lmbda = int(lmbda)\n",
        "        self.sigma_log = sigma_log\n",
        "        self.dT = int(dT)\n",
        "        self.toolbox = base.Toolbox()\n",
        "        if self.log:\n",
        "            self._ab_log = (math.log10(self.ab[0]), math.log10(self.ab[1]))\n",
        "            self._eb_log = (math.log10(self.eb[0]), math.log10(self.eb[1]))\n",
        "        else:\n",
        "            self._ab_log = self.ab\n",
        "            self._eb_log = self.eb\n",
        "        random.seed(self.seed)\n",
        "        np.random.seed(self.seed)\n",
        "        self.toolbox.register(\"attr_T\", random.randint, self.Tb[0], self.Tb[1])\n",
        "        self.toolbox.register(\"attr_a\", random.uniform, self._ab_log[0], self._ab_log[1])\n",
        "        self.toolbox.register(\"attr_e\", random.uniform, self._eb_log[0], self._eb_log[1])\n",
        "        self.toolbox.register(\"individual\", tools.initCycle, creator.Individual, (self.toolbox.attr_T, self.toolbox.attr_a, self.toolbox.attr_e), n=1)\n",
        "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
        "        self.toolbox.register(\"evaluate\", self._evaluate)\n",
        "\n",
        "    def _clamp(self, ind):\n",
        "        ind[0] = _clamp(int(round(ind[0])), self.Tb[0], self.Tb[1])\n",
        "        ind[1] = _clamp(ind[1], self._ab_log[0], self._ab_log[1])\n",
        "        ind[2] = _clamp(ind[2], self._eb_log[0], self._eb_log[1])\n",
        "\n",
        "    def _decode(self, ind):\n",
        "        T = int(round(ind[0]))\n",
        "        T = _clamp(T, self.Tb[0], self.Tb[1])\n",
        "        if self.log:\n",
        "            a = 10.0 ** _clamp(ind[1], self._ab_log[0], self._ab_log[1])\n",
        "            e = 10.0 ** _clamp(ind[2], self._eb_log[0], self._eb_log[1])\n",
        "        else:\n",
        "            a = _clamp(ind[1], self.ab[0], self.ab[1])\n",
        "            e = _clamp(ind[2], self.eb[0], self.eb[1])\n",
        "        return T, float(a), float(e)\n",
        "\n",
        "    def _evaluate(self, ind):\n",
        "        T, a, e = self._decode(ind)\n",
        "        try:\n",
        "            v = float(self.obj(T, a, e))\n",
        "        except Exception:\n",
        "            v = float(\"inf\")\n",
        "        return (v,)\n",
        "\n",
        "    def _mut(self, parent):\n",
        "        child = creator.Individual(parent[:])\n",
        "        child[0] = int(round(child[0] + random.randint(-self.dT, self.dT)))\n",
        "        child[1] = child[1] + random.gauss(0.0, self.sigma_log)\n",
        "        child[2] = child[2] + random.gauss(0.0, self.sigma_log)\n",
        "        self._clamp(child)\n",
        "        return child\n",
        "\n",
        "    def run(self, steps=24):\n",
        "        parents = self.toolbox.population(n=self.mu)\n",
        "        history = []\n",
        "        t0 = time.perf_counter()\n",
        "        cum_time = 0.0\n",
        "        for ind in parents:\n",
        "            ind.fitness.values = self.toolbox.evaluate(ind)\n",
        "        best_sofar = min(parents, key=lambda x: x.fitness.values[0])\n",
        "        for s in range(steps):\n",
        "            gs = time.perf_counter()\n",
        "            off = []\n",
        "            for _ in range(self.lmbda):\n",
        "                p = random.choice(parents)\n",
        "                c = self._mut(p)\n",
        "                c.fitness.values = self.toolbox.evaluate(c)\n",
        "                off.append(c)\n",
        "            pool = parents + off\n",
        "            pool.sort(key=lambda x: x.fitness.values[0])\n",
        "            parents = [creator.Individual(ind[:]) for ind in pool[:self.mu]]\n",
        "            for i in range(self.mu):\n",
        "                parents[i].fitness.values = pool[i].fitness.values\n",
        "            cur_best = parents[0]\n",
        "            if cur_best.fitness.values[0] < best_sofar.fitness.values[0]:\n",
        "                best_sofar = cur_best\n",
        "            step_time = time.perf_counter() - gs\n",
        "            cum_time = time.perf_counter() - t0\n",
        "            vals = [ind.fitness.values[0] for ind in parents]\n",
        "            Tb, ab, eb = self._decode(best_sofar)\n",
        "            history.append({\n",
        "                \"iter\": s,\n",
        "                \"best_ppl_sofar\": best_sofar.fitness.values[0],\n",
        "                \"pop_mean\": float(np.mean(vals)),\n",
        "                \"pop_std\": float(np.std(vals)),\n",
        "                \"T_best\": Tb,\n",
        "                \"alpha_best\": ab,\n",
        "                \"eta_best\": eb,\n",
        "                \"step_time\": step_time,\n",
        "                \"cum_time\": cum_time\n",
        "            })\n",
        "        best = self._decode(best_sofar)\n",
        "        best_val = best_sofar.fitness.values[0]\n",
        "        final_T = best[0]\n",
        "        first_hit = None\n",
        "        for row in history:\n",
        "            if row[\"T_best\"] == final_T:\n",
        "                first_hit = row[\"cum_time\"]\n",
        "                break\n",
        "        return {\n",
        "            \"best\": {\"T\": best[0], \"alpha\": best[1], \"eta\": best[2], \"ppl\": best_val},\n",
        "            \"history\": history,\n",
        "            \"total_time\": history[-1][\"cum_time\"] if history else 0.0,\n",
        "            \"time_to_best_T\": first_hit if first_hit is not None else None\n",
        "        }"
      ],
      "metadata": {
        "id": "LCHio8DsqM9c"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "EVAL_CACHE = {}\n",
        "\n",
        "def _doc_perplexities(lda, X, batch_size=1024, eps=1e-300):\n",
        "    phi = lda.components_.astype(np.float64)\n",
        "    phi /= phi.sum(axis=1, keepdims=True)\n",
        "    n = X.shape[0]\n",
        "    out = np.empty(n, dtype=np.float64)\n",
        "    for s in range(0, n, batch_size):\n",
        "        e = min(n, s + batch_size)\n",
        "        Xb = X[s:e]\n",
        "        theta = lda.transform(Xb)\n",
        "        theta = np.clip(theta, 1e-12, None)\n",
        "        for i in range(Xb.shape[0]):\n",
        "            row = Xb[i]\n",
        "            idx = row.indices\n",
        "            dat = row.data\n",
        "            if dat.size == 0:\n",
        "                out[s + i] = 1.0\n",
        "                continue\n",
        "            p = theta[i].dot(phi[:, idx])\n",
        "            p = np.clip(p, eps, None)\n",
        "            ll = float((np.log(p) * dat).sum())\n",
        "            cnt = float(dat.sum())\n",
        "            out[s + i] = math.exp(-ll / max(cnt, 1.0))\n",
        "    return out\n",
        "\n",
        "def _fit_eval_full(T, alpha, eta, seed=42, max_iter=400, batch_size=2048, learning_method=\"online\"):\n",
        "    key = (int(T), float(alpha), float(eta), int(seed), int(max_iter), int(batch_size), learning_method)\n",
        "    if key in EVAL_CACHE:\n",
        "        return EVAL_CACHE[key]\n",
        "    lda = LatentDirichletAllocation(\n",
        "        n_components=int(T),\n",
        "        doc_topic_prior=float(alpha),\n",
        "        topic_word_prior=float(eta),\n",
        "        learning_method=learning_method,\n",
        "        max_iter=int(max_iter),\n",
        "        batch_size=int(batch_size),\n",
        "        random_state=int(seed),\n",
        "        evaluate_every=-1,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    t0 = time.perf_counter()\n",
        "    lda.fit(Xtr)\n",
        "    fit_time = time.perf_counter() - t0\n",
        "    t1 = time.perf_counter()\n",
        "    corpus_ppl = float(lda.perplexity(Xva))\n",
        "    doc_ppl = _doc_perplexities(lda, Xva, batch_size=min(1024, Xva.shape[0]))\n",
        "    eval_time = time.perf_counter() - t1\n",
        "    res = {\n",
        "        \"T\": int(T),\n",
        "        \"alpha\": float(alpha),\n",
        "        \"eta\": float(eta),\n",
        "        \"corpus_ppl\": corpus_ppl,\n",
        "        \"doc_ppl_mean\": float(np.mean(doc_ppl)),\n",
        "        \"doc_ppl_max\": float(np.max(doc_ppl)),\n",
        "        \"fit_time\": fit_time,\n",
        "        \"eval_time\": eval_time,\n",
        "        \"n_iter_lda\": getattr(lda, \"n_iter_\", None)\n",
        "    }\n",
        "    EVAL_CACHE[key] = res\n",
        "    return res\n",
        "\n",
        "def make_objective(seed=42, max_iter=400, batch_size=2048, learning_method=\"online\"):\n",
        "    def objective(T, a, e):\n",
        "        r = _fit_eval_full(T, a, e, seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
        "        return r[\"corpus_ppl\"]\n",
        "    return objective\n",
        "\n",
        "def _ensure_dir(p):\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def _write_history_csv(history_rows, path):\n",
        "    fields = [\"iter\",\"best_corpus_ppl\",\"best_doc_ppl_max\",\"pop_mean\",\"pop_std\",\"T_best\",\"alpha_best\",\"eta_best\",\"step_time\",\"cum_time\"]\n",
        "    with open(path, \"w\", newline=\"\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=fields)\n",
        "        w.writeheader()\n",
        "        for row in history_rows:\n",
        "            w.writerow(row)\n",
        "\n",
        "def _plot_series(xs, ys, xlabel, ylabel, title, path):\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(xs, ys, marker=\"o\", linewidth=1.5)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "def run_ga_with_logging(\n",
        "    outdir,\n",
        "    gens=24,\n",
        "    pop_size=24,\n",
        "    T_bounds=(10,200),\n",
        "    alpha_bounds=(1e-3,1.0),\n",
        "    eta_bounds=(1e-3,1.0),\n",
        "    seed=42,\n",
        "    max_iter=400,\n",
        "    batch_size=2048,\n",
        "    learning_method=\"online\",\n",
        "    cxpb=0.9,\n",
        "    mutpb=0.2,\n",
        "    tournsize=3,\n",
        "    elite=2,\n",
        "    sigma_log=0.25,\n",
        "    dT=5\n",
        "):\n",
        "    _ensure_dir(outdir)\n",
        "    obj = make_objective(seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
        "    ga = GAOptimizer(\n",
        "        obj,\n",
        "        T_bounds=T_bounds,\n",
        "        alpha_bounds=alpha_bounds,\n",
        "        eta_bounds=eta_bounds,\n",
        "        log_space=True,\n",
        "        seed=seed,\n",
        "        cxpb=cxpb,\n",
        "        mutpb=mutpb,\n",
        "        tournsize=tournsize,\n",
        "        elite=elite,\n",
        "        sigma_log=sigma_log,\n",
        "        dT=dT\n",
        "    )\n",
        "    res = ga.run(gens=gens, pop_size=pop_size)\n",
        "    hist = []\n",
        "    for row in res[\"history\"]:\n",
        "        T = row[\"T_best\"]\n",
        "        a = row[\"alpha_best\"]\n",
        "        e = row[\"eta_best\"]\n",
        "        r = _fit_eval_full(T, a, e, seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
        "        hist.append({\n",
        "            \"iter\": row[\"iter\"],\n",
        "            \"best_corpus_ppl\": float(r[\"corpus_ppl\"]),\n",
        "            \"best_doc_ppl_max\": float(r[\"doc_ppl_max\"]),\n",
        "            \"pop_mean\": row[\"pop_mean\"],\n",
        "            \"pop_std\": row[\"pop_std\"],\n",
        "            \"T_best\": int(T),\n",
        "            \"alpha_best\": float(a),\n",
        "            \"eta_best\": float(e),\n",
        "            \"step_time\": row[\"step_time\"],\n",
        "            \"cum_time\": row[\"cum_time\"]\n",
        "        })\n",
        "    _write_history_csv(hist, os.path.join(outdir, \"history.csv\"))\n",
        "    xs = [h[\"iter\"] for h in hist]\n",
        "    ys_mean = [h[\"best_corpus_ppl\"] for h in hist]\n",
        "    ys_max = [h[\"best_doc_ppl_max\"] for h in hist]\n",
        "    _plot_series(xs, ys_mean, \"iter\", \"perplexity\", \"GA: mean perplexity vs iter\", os.path.join(outdir, \"mean_ppl.png\"))\n",
        "    _plot_series(xs, ys_max, \"iter\", \"perplexity\", \"GA: max doc perplexity vs iter\", os.path.join(outdir, \"max_ppl.png\"))\n",
        "    avg_step_time = float(np.mean([h[\"step_time\"] for h in hist])) if hist else 0.0\n",
        "    summary = {\n",
        "        \"best\": res[\"best\"],\n",
        "        \"avg_step_time\": avg_step_time,\n",
        "        \"total_time\": res[\"total_time\"],\n",
        "        \"time_to_best_T\": res[\"time_to_best_T\"]\n",
        "    }\n",
        "    with open(os.path.join(outdir, \"summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    return {\"history\": hist, \"summary\": summary}\n",
        "\n",
        "def run_es_with_logging(\n",
        "    outdir,\n",
        "    steps=24,\n",
        "    T_bounds=(10,200),\n",
        "    alpha_bounds=(1e-3,1.0),\n",
        "    eta_bounds=(1e-3,1.0),\n",
        "    seed=42,\n",
        "    max_iter=400,\n",
        "    batch_size=2048,\n",
        "    learning_method=\"online\",\n",
        "    mu=12,\n",
        "    lmbda=48,\n",
        "    sigma_log=0.25,\n",
        "    dT=5\n",
        "):\n",
        "    _ensure_dir(outdir)\n",
        "    obj = make_objective(seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
        "    es = ESOptimizer(\n",
        "        obj,\n",
        "        T_bounds=T_bounds,\n",
        "        alpha_bounds=alpha_bounds,\n",
        "        eta_bounds=eta_bounds,\n",
        "        log_space=True,\n",
        "        seed=seed,\n",
        "        mu=mu,\n",
        "        lmbda=lmbda,\n",
        "        sigma_log=sigma_log,\n",
        "        dT=dT\n",
        "    )\n",
        "    res = es.run(steps=steps)\n",
        "    hist = []\n",
        "    for row in res[\"history\"]:\n",
        "        T = row[\"T_best\"]\n",
        "        a = row[\"alpha_best\"]\n",
        "        e = row[\"eta_best\"]\n",
        "        r = _fit_eval_full(T, a, e, seed=seed, max_iter=max_iter, batch_size=batch_size, learning_method=learning_method)\n",
        "        hist.append({\n",
        "            \"iter\": row[\"iter\"],\n",
        "            \"best_corpus_ppl\": float(r[\"corpus_ppl\"]),\n",
        "            \"best_doc_ppl_max\": float(r[\"doc_ppl_max\"]),\n",
        "            \"pop_mean\": row[\"pop_mean\"],\n",
        "            \"pop_std\": row[\"pop_std\"],\n",
        "            \"T_best\": int(T),\n",
        "            \"alpha_best\": float(a),\n",
        "            \"eta_best\": float(e),\n",
        "            \"step_time\": row[\"step_time\"],\n",
        "            \"cum_time\": row[\"cum_time\"]\n",
        "        })\n",
        "    _write_history_csv(hist, os.path.join(outdir, \"history.csv\"))\n",
        "    xs = [h[\"iter\"] for h in hist]\n",
        "    ys_mean = [h[\"best_corpus_ppl\"] for h in hist]\n",
        "    ys_max = [h[\"best_doc_ppl_max\"] for h in hist]\n",
        "    _plot_series(xs, ys_mean, \"iter\", \"perplexity\", \"ES: mean perplexity vs iter\", os.path.join(outdir, \"mean_ppl.png\"))\n",
        "    _plot_series(xs, ys_max, \"iter\", \"perplexity\", \"ES: max doc perplexity vs iter\", os.path.join(outdir, \"max_ppl.png\"))\n",
        "    avg_step_time = float(np.mean([h[\"step_time\"] for h in hist])) if hist else 0.0\n",
        "    summary = {\n",
        "        \"best\": res[\"best\"],\n",
        "        \"avg_step_time\": avg_step_time,\n",
        "        \"total_time\": res[\"total_time\"],\n",
        "        \"time_to_best_T\": res[\"time_to_best_T\"]\n",
        "    }\n",
        "    with open(os.path.join(outdir, \"summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    return {\"history\": hist, \"summary\": summary}\n"
      ],
      "metadata": {
        "id": "eE0uE7RHrloY"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"runs/agnews\"\n",
        "\n",
        "ga_out = run_ga_with_logging(\n",
        "    outdir=f\"{BASE_DIR}/ga\",\n",
        "    gens=24,\n",
        "    pop_size=24,\n",
        "    seed=42,\n",
        "    max_iter=400,\n",
        "    batch_size=2048,\n",
        "    learning_method=\"online\"\n",
        ")\n",
        "\n",
        "es_out = run_es_with_logging(\n",
        "    outdir=f\"{BASE_DIR}/es\",\n",
        "    steps=24,\n",
        "    seed=42,\n",
        "    max_iter=400,\n",
        "    batch_size=2048,\n",
        "    learning_method=\"online\"\n",
        ")\n",
        "\n",
        "print(\"GA summary:\", ga_out[\"summary\"])\n",
        "print(\"ES summary:\", es_out[\"summary\"])"
      ],
      "metadata": {
        "id": "9IY9-TT8stTs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}